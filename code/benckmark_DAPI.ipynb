{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0756a232",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pyvips\n",
        "import seaborn as sns\n",
        "import tifffile\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91d81aee",
      "metadata": {},
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "990a340d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mosaic_DAPI_MIP.tif',\n",
              " 'mosaic_DAPI_z0.tif',\n",
              " 'mosaic_DAPI_z1.tif',\n",
              " 'mosaic_DAPI_z2.tif',\n",
              " 'mosaic_DAPI_z3.tif',\n",
              " 'mosaic_DAPI_z4.tif',\n",
              " 'mosaic_DAPI_z5.tif',\n",
              " 'mosaic_DAPI_z6.tif']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# File paths\n",
        "dataset = \"MERSCOPE_WT_1\"\n",
        "data_path = f\"../data/{dataset}/\"\n",
        "output_path = f\"../output/{dataset}/\"\n",
        "\n",
        "# Transformation parameters\n",
        "pixel_size = 0.10799861\n",
        "x_shift = int(-266.1734)\n",
        "y_shift = int(180.2510)\n",
        "\n",
        "# All DAPI images\n",
        "files = os.listdir(data_path + \"raw_data/DAPI_images/\")\n",
        "files = [i for i in files if i.startswith(\"mosaic\")]\n",
        "files.sort()\n",
        "files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d213bca",
      "metadata": {},
      "source": [
        "### Derive the MIP of DAPI images (run once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "83822b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# paths = [data_path + \"raw_data/DAPI_images/\" + f\"mosaic_DAPI_z{i}.tif\" for i in range(7)]\n",
        "# imgs = [pyvips.Image.new_from_file(p, access=\"sequential\") for p in paths]\n",
        "# mip = imgs[0]\n",
        "# for im in imgs[1:]:\n",
        "#     mip = pyvips.Image.maxpair(mip, im)\n",
        "# mip.tiffsave(\n",
        "#     data_path + \"raw_data/DAPI_images/mosaic_DAPI_MIP.tif\",\n",
        "#     bigtiff=True,\n",
        "#     compression=\"lzw\",   # or \"deflate\"\n",
        "#     tile=True,\n",
        "#     tile_width=1024,\n",
        "#     tile_height=1024,\n",
        "#     pyramid=False\n",
        "# )\n",
        "# print(\"Saved:\", \"mosaic_DAPI_MIP.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393e1aeb",
      "metadata": {},
      "source": [
        "### [Benchmark I] Area of detected objects on the MIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0813b103",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== Helper functions ==================== #\n",
        "\n",
        "\n",
        "# Thresholding followed by dilation with circular kernel\n",
        "def adaptive_thresholding_with_dilation(img, block_size=49, c=-1, radius=10):\n",
        "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(th, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "def adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=50, radius=10):\n",
        "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
        "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    filtered_contours = [c for c in contours if cv2.contourArea(c) >= min_area]\n",
        "    filtered_img = np.zeros_like(th)\n",
        "    cv2.drawContours(filtered_img, filtered_contours, -1, 255, -1)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(filtered_img, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "def otsu_with_dilation(img, radius=10):\n",
        "    _, th = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(th, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "# Analyze detected objects\n",
        "def analyze_objects(contours, method_name):\n",
        "    objects = []\n",
        "    for i, contour in enumerate(contours):\n",
        "        area_pixels = cv2.contourArea(contour)\n",
        "        if area_pixels > 0:\n",
        "            area_um2 = area_pixels * (pixel_size ** 2)\n",
        "            radius_um = np.sqrt(area_um2 / np.pi)\n",
        "            diameter_um = radius_um * 2\n",
        "            objects.append({\"method\": method_name,\n",
        "                            \"object_id\": i + 1,\n",
        "                            \"area_pixels\": area_pixels,\n",
        "                            \"area_um2\": area_um2,\n",
        "                            \"radius_um\": radius_um,\n",
        "                            \"diameter_um\": diameter_um})\n",
        "    return objects\n",
        "\n",
        "\n",
        "def print_method_results(objects, method_name):\n",
        "    \n",
        "    if len(objects) > 0:\n",
        "        \n",
        "        print(f\"Number of detected objects: {len(objects)}\")\n",
        "        print(f\"\\nDetailed statistics for each object:\")\n",
        "        \n",
        "        areas_px = [obj[\"area_pixels\"] for obj in objects]\n",
        "        areas_um2 = [obj[\"area_um2\"] for obj in objects]\n",
        "        radii_um = [obj[\"radius_um\"] for obj in objects]\n",
        "        diameters_um = [obj[\"diameter_um\"] for obj in objects]\n",
        "        \n",
        "        print(f\"\\nSummary statistics:\")\n",
        "        print(f\"  Area (pixels²):  Mean={np.mean(areas_px):6.1f}, Median={np.median(areas_px):6.1f}, Min={np.min(areas_px):6.1f}, Max={np.max(areas_px):6.1f}\")\n",
        "        print(f\"  Area (μm²):      Mean={np.mean(areas_um2):6.2f}, Median={np.median(areas_um2):6.2f}, Min={np.min(areas_um2):6.2f}, Max={np.max(areas_um2):6.2f}\")\n",
        "        print(f\"  Radius (μm):     Mean={np.mean(radii_um):6.2f}, Median={np.median(radii_um):6.2f}, Min={np.min(radii_um):6.2f}, Max={np.max(radii_um):6.2f}\")\n",
        "        print(f\"  Diameter (μm):   Mean={np.mean(diameters_um):6.2f}, Median={np.median(diameters_um):6.2f}, Min={np.min(diameters_um):6.2f}, Max={np.max(diameters_um):6.2f}\")\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        print(f\"No objects detected with {method_name}!\")\n",
        "\n",
        "\n",
        "# Extract statistics for plotting\n",
        "def get_method_statistics(method_results, method_name, stat_type=\"area_pixels\"):\n",
        "    if method_name not in method_results:\n",
        "        print(f\"Method '{method_name}' not found in results\")\n",
        "        return []\n",
        "    objects = method_results[method_name][\"objects\"]\n",
        "    return [obj[stat_type] for obj in objects]\n",
        "\n",
        "\n",
        "def get_all_methods_statistics(method_results, stat_type=\"area_pixels\"):\n",
        "    stats_dict = {}\n",
        "    for method_name in method_results.keys():\n",
        "        stats_dict[method_name] = get_method_statistics(method_results, method_name, stat_type)\n",
        "    return stats_dict\n",
        "\n",
        "\n",
        "# Downsample image\n",
        "def downsample_image(img, scale_factor=5000):\n",
        "    height, width = img.shape\n",
        "    if height < width:\n",
        "        scale_factor = 5000 / height\n",
        "        new_height = 5000\n",
        "        new_width = int(width * scale_factor)\n",
        "    else:\n",
        "        scale_factor = 5000 / width\n",
        "        new_width = 5000\n",
        "        new_height = int(height * scale_factor)\n",
        "    return cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d470d223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize for comparison\n",
        "fname = \"mosaic_DAPI_MIP.tif\"\n",
        "\n",
        "# Load DAPI image, downsample, and save representative patch\n",
        "img_path = os.path.join(data_path, \"raw_data/DAPI_images\", fname)\n",
        "img = tifffile.imread(img_path)\n",
        "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "img_downsampled = downsample_image(img, scale_factor=5000)\n",
        "cv2.imwrite(output_path + f\"downsampled_img.png\", img_downsampled)\n",
        "\n",
        "target_coords = [(3750, 1500), (3750, 1650), (3750, 1800)]\n",
        "w, h = 150, 150\n",
        "for i, (x0, y0) in enumerate(target_coords):\n",
        "    patch = img_downsampled[y0:y0+h, x0:x0+w]\n",
        "    cv2.imwrite(output_path + f\"downsampled_patch_{i}.png\", patch)\n",
        "\n",
        "print(f\"Analyzing DAPI image: {fname}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define thresholding methods\n",
        "thresholding_methods = {\n",
        "    \"Adaptive Thresholding\": {\n",
        "        \"function\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 49, -1),\n",
        "        \"description\": \"Gaussian-weighted adaptive thresholding with block size 49\"\n",
        "    },\n",
        "    \"Adaptive + Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_dilation(img, block_size=49, c=-1, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Small Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=5),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Large Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=15),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Moderate Size Filter + Small Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=5),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=250px)\"\n",
        "    },\n",
        "    \"Adaptive + Moderate Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=250px)\"\n",
        "    },\n",
        "    \"Adaptive + Moderate Size Filter + Large Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=15),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=250px)\"\n",
        "    },\n",
        "    \"Adaptive + Large Size Filter + Small Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=5),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=500px)\"\n",
        "    },\n",
        "    \"Adaptive + Large Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=500px)\"\n",
        "    },\n",
        "    \"Adaptive + Large Size Filter + Large Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=15),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=500px)\"\n",
        "    },\n",
        "    \"Otsu Thresholding\": {\n",
        "        \"function\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
        "        \"description\": \"Automatic global thresholding using Otsu's method\"\n",
        "    },\n",
        "    \"Otsu + Dilation\": {\n",
        "        \"function\": lambda img: otsu_with_dilation(img, radius=10),\n",
        "        \"description\": \"Otsu thresholding followed by dilation with circular kernel (radius=10px)\"\n",
        "    },\n",
        "}\n",
        "\n",
        "print(f\"Total methods available: {list(thresholding_methods.keys())}\")\n",
        "\n",
        "# Main analysis loop\n",
        "all_results = {}\n",
        "\n",
        "for i, (method_name, method_info) in enumerate(thresholding_methods.items()):\n",
        "    print(f\"METHOD {i+1}: {method_name.upper()}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Description: {method_info['description']}\")\n",
        "    \n",
        "    # Apply thresholding method\n",
        "    thresholded_img = method_info[\"function\"](img)\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresholded_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    # Save downsampled thresholded image\n",
        "    thresholded_img_downsampled = downsample_image(thresholded_img, scale_factor=5000)\n",
        "    safe_filename = method_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    cv2.imwrite(output_path + f\"thresholded_img_{safe_filename}_downsampled.png\", thresholded_img_downsampled)\n",
        "    \n",
        "    for i, (x0, y0) in enumerate(target_coords):\n",
        "        patch = thresholded_img_downsampled[y0:y0+h, x0:x0+w]\n",
        "        cv2.imwrite(output_path + f\"thresholded_patch_{safe_filename}_downsampled_{i}.png\", patch)\n",
        "    \n",
        "    # Analyze objects\n",
        "    objects = analyze_objects(contours, method_name)\n",
        "    \n",
        "    # Print results\n",
        "    print_method_results(objects, method_name)\n",
        "    \n",
        "    # Store results\n",
        "    all_results[method_name] = {\n",
        "        \"objects\": objects,\n",
        "        \"thresholded_image\": thresholded_img,\n",
        "        \"num_objects\": len(objects)\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Method Comparison Summary\n",
        "print(\"COMPARISON SUMMARY\")\n",
        "print(\"-\" * 40)\n",
        "for method_name, results in all_results.items():\n",
        "    print(f\"{method_name}: {results['num_objects']} objects detected\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Store results for further analysis\n",
        "method_results = all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0aeeff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save object areas\n",
        "areas_um2 = get_all_methods_statistics(method_results, \"area_um2\")\n",
        "areas_MERSCOPE = areas_um2[\"Adaptive + Small Size Filter + Moderate Dilation\"]\n",
        "pd.DataFrame({\"area\": areas_MERSCOPE}).to_csv(\"../validation/areas_MERSCOPE.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2594ad6",
      "metadata": {},
      "source": [
        "### [Benchmark 2] In-soma ratio of transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "99fcbdc0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cell_id</th>\n",
              "      <th>gene</th>\n",
              "      <th>global_x</th>\n",
              "      <th>global_y</th>\n",
              "      <th>global_z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>Inpp4b</td>\n",
              "      <td>133.08844</td>\n",
              "      <td>2717.2595</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1</td>\n",
              "      <td>Inpp4b</td>\n",
              "      <td>187.72237</td>\n",
              "      <td>2653.8596</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4388284201180100135</td>\n",
              "      <td>Inpp4b</td>\n",
              "      <td>69.97584</td>\n",
              "      <td>2656.0925</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>Inpp4b</td>\n",
              "      <td>170.35840</td>\n",
              "      <td>2744.3406</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1</td>\n",
              "      <td>Gfap</td>\n",
              "      <td>90.94957</td>\n",
              "      <td>2735.0588</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               cell_id    gene   global_x   global_y  global_z\n",
              "0                   -1  Inpp4b  133.08844  2717.2595       0.0\n",
              "1                   -1  Inpp4b  187.72237  2653.8596       1.0\n",
              "2  4388284201180100135  Inpp4b   69.97584  2656.0925       1.0\n",
              "3                   -1  Inpp4b  170.35840  2744.3406       1.0\n",
              "4                   -1    Gfap   90.94957  2735.0588       2.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read transcripts\n",
        "transcripts = pd.read_csv(data_path + \"raw_data/transcripts.csv\")\n",
        "transcripts = transcripts[[\"cell_id\", \"gene\", \"global_x\", \"global_y\", \"global_z\"]].copy()\n",
        "transcripts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ed1b8036",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define target genes\n",
        "all_genes = pd.read_csv(data_path + \"processed_data/genes.csv\")\n",
        "all_genes = all_genes[\"genes\"].tolist()\n",
        "\n",
        "with open(\"../data/utils/overlap_genes.pickle\", \"rb\") as handle:\n",
        "    overlap_genes = pickle.load(handle)\n",
        "granule_markers = overlap_genes[\"overlap_genes_select\"]\n",
        "\n",
        "transcripts = transcripts[transcripts[\"gene\"].isin(all_genes)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30aa53e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting thresholding methods benchmarking...\n",
            "\n",
            "Processing method 1/3: Adaptive Thresholding\n",
            "Processing method 2/3: Adaptive + Small Size Filter + Moderate Dilation\n"
          ]
        }
      ],
      "source": [
        "# ==================== Thresholding Methods Benchmarking ====================#\n",
        "\n",
        "# Define thresholding methods\n",
        "thresholding_methods = {\n",
        "    \"Adaptive Thresholding\": {\n",
        "        \"function\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 49, -1),\n",
        "        \"description\": \"Gaussian-weighted adaptive thresholding with block size 49\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + large Size Filter + Very Large Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=20),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=20px) and size filter (min_area=500px)\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Initialize transcript dataframe with binary columns for each method\n",
        "transcripts_with_labels = transcripts.copy()\n",
        "for method_name in thresholding_methods.keys():\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    transcripts_with_labels[f\"in_soma_{safe_col_name}\"] = 0\n",
        "\n",
        "print(\"Starting thresholding methods benchmarking...\\n\")\n",
        "\n",
        "# Process each z-layer (exclude MIP file)\n",
        "z_layer_files = [f for f in files if f.startswith(\"mosaic_DAPI_z\")]\n",
        "z_layer_files.sort()\n",
        "\n",
        "# Process each thresholding method\n",
        "for method_idx, (method_name, method_info) in enumerate(thresholding_methods.items()):\n",
        "    print(f\"Processing method {method_idx+1}/{len(thresholding_methods)}: {method_name}\")\n",
        "    \n",
        "    # Get safe column name for this method\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    in_soma_col = f\"in_soma_{safe_col_name}\"\n",
        "    \n",
        "    for j, fname in enumerate(z_layer_files):\n",
        "        # Load DAPI image\n",
        "        img_path = os.path.join(data_path, \"raw_data/DAPI_images\", fname)\n",
        "        img = tifffile.imread(img_path)\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "        \n",
        "        # Apply thresholding method\n",
        "        th = method_info[\"function\"](img)\n",
        "        \n",
        "        # Map transcripts to this z-layer and check overlap\n",
        "        trans_z_mask = transcripts[\"global_z\"] == j\n",
        "        trans_z_indices = transcripts.index[trans_z_mask].values\n",
        "        \n",
        "        if len(trans_z_indices) > 0:\n",
        "            # Calculate row and col from global_x and global_y\n",
        "            # Convert global coordinates (in microns) to pixel coordinates\n",
        "            global_x_vals = transcripts.loc[trans_z_indices, \"global_x\"].values\n",
        "            global_y_vals = transcripts.loc[trans_z_indices, \"global_y\"].values\n",
        "            \n",
        "            # Convert to pixel coordinates (divide by pixel_size)\n",
        "            col_vals = (global_x_vals / pixel_size).astype(int)\n",
        "            row_vals = (global_y_vals / pixel_size).astype(int)\n",
        "            \n",
        "            # Avoid out-of-bounds indexing\n",
        "            height, width = th.shape\n",
        "            valid = (row_vals >= 0) & (row_vals < height) & (col_vals >= 0) & (col_vals < width)\n",
        "            row_valid = row_vals[valid]\n",
        "            col_valid = col_vals[valid]\n",
        "            valid_indices = trans_z_indices[valid]\n",
        "            \n",
        "            # Check overlap for valid transcripts\n",
        "            if len(row_valid) > 0:\n",
        "                overlaps = (th[row_valid, col_valid] != 0).astype(int)\n",
        "                # Update in-soma labels in the transcript dataframe\n",
        "                transcripts_with_labels.loc[valid_indices, in_soma_col] = overlaps\n",
        "\n",
        "print(\"Completed processing all methods.\\n\")\n",
        "\n",
        "# Calculate per-gene in-soma ratios for each method\n",
        "gene_ratios = []\n",
        "\n",
        "for method_name in thresholding_methods.keys():\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    in_soma_col = f\"in_soma_{safe_col_name}\"\n",
        "    \n",
        "    # Group by gene and calculate in-soma ratio\n",
        "    gene_stats = transcripts_with_labels.groupby(\"gene\").agg({\n",
        "        in_soma_col: [\"sum\", \"count\"]\n",
        "    }).reset_index()\n",
        "    gene_stats.columns = [\"gene\", \"in_soma_count\", \"total_count\"]\n",
        "    gene_stats[\"in_soma_ratio\"] = gene_stats[\"in_soma_count\"] / gene_stats[\"total_count\"]\n",
        "    gene_stats[\"method\"] = method_name\n",
        "    \n",
        "    gene_ratios.append(gene_stats)\n",
        "\n",
        "# Combine all gene ratios\n",
        "gene_ratios_df = pd.concat(gene_ratios, ignore_index=True)\n",
        "\n",
        "# Add gene category labels\n",
        "gene_ratios_df[\"gene_category\"] = \"Others\"\n",
        "gene_ratios_df.loc[gene_ratios_df[\"gene\"].isin(granule_markers), \"gene_category\"] = \"Granule Markers\"\n",
        "\n",
        "# Save transcript file with in-soma labels\n",
        "transcripts_output_path = os.path.join(data_path, \"processed_data\", \"transcripts_with_in_soma_labels.parquet\")\n",
        "transcripts_with_labels.to_parquet(transcripts_output_path)\n",
        "print(f\"Transcripts with in-soma labels saved to: {transcripts_output_path}\")\n",
        "\n",
        "# Save gene-level in-soma ratios\n",
        "gene_ratios_output_path = os.path.join(output_path, \"gene_in_soma_ratios.csv\")\n",
        "gene_ratios_df.to_csv(gene_ratios_output_path, index=False)\n",
        "print(f\"Gene-level in-soma ratios saved to: {gene_ratios_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cb87fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== Visualization: Grouped Box Plot ====================#\n",
        "\n",
        "# Prepare data for plotting\n",
        "plot_data = gene_ratios_df.copy()\n",
        "\n",
        "# Define the order of categories and methods\n",
        "category_order = [\"Granule Markers\", \"Others\"]\n",
        "method_order = list(thresholding_methods.keys())\n",
        "\n",
        "# Create the grouped box plot\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Set up positions for grouped boxes\n",
        "n_categories = len(category_order)\n",
        "n_methods = len(method_order)\n",
        "box_width = 0.35\n",
        "positions_base = np.arange(n_categories)\n",
        "\n",
        "# Prepare data for each group\n",
        "plot_data_list = []\n",
        "positions_list = []\n",
        "colors_list = []\n",
        "labels_list = []\n",
        "\n",
        "for i, category in enumerate(category_order):\n",
        "    for j, method in enumerate(method_order):\n",
        "        category_data = plot_data[(plot_data[\"gene_category\"] == category) & (plot_data[\"method\"] == method)]\n",
        "        if len(category_data) > 0:\n",
        "            plot_data_list.append(category_data[\"in_soma_ratio\"].values)\n",
        "            # Position: base position + offset for method\n",
        "            offset = (j - (n_methods - 1) / 2) * box_width\n",
        "            positions_list.append(positions_base[i] + offset)\n",
        "            colors_list.append(['#3498db', '#e74c3c'][j])  # Blue and red for the two methods\n",
        "\n",
        "# Create box plot\n",
        "bp = ax.boxplot(plot_data_list, positions=positions_list, widths=box_width*0.8, \n",
        "                patch_artist=True, showmeans=True, meanline=True)\n",
        "\n",
        "# Color the boxes by method\n",
        "for i, patch in enumerate(bp['boxes']):\n",
        "    patch.set_facecolor(colors_list[i])\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "# Set x-axis labels (category names only)\n",
        "ax.set_xticks(positions_base)\n",
        "ax.set_xticklabels(category_order, fontsize=11)\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_ylabel('In-Soma Ratio', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Gene Category', fontsize=12, fontweight='bold')\n",
        "ax.set_title('Distribution of In-Soma Ratios by Gene Category and Thresholding Method', \n",
        "             fontsize=14, pad=20, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3, axis='y', linestyle='--')\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=['#3498db', '#e74c3c'][i], alpha=0.7, label=method) \n",
        "                   for i, method in enumerate(method_order)]\n",
        "ax.legend(handles=legend_elements, loc='upper right', title='Thresholding Method', \n",
        "          title_fontsize=11, fontsize=10, framealpha=0.9)\n",
        "\n",
        "# Set y-axis limits\n",
        "ax.set_ylim([0, 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "plot_output_path = os.path.join(output_path, \"in_soma_ratio_comparison.png\")\n",
        "plt.savefig(plot_output_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"Box plot saved to: {plot_output_path}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1da560",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mcDETECT-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
