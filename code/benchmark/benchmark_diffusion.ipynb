{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Benchmark: Granule enrichment vs. extrasomatic baseline\n",
        "\n",
        "Benchmarks whether detected RNA granules are enriched beyond the ambient extrasomatic baseline. Uses **composition-based logFC** for both metrics so they are comparable. Granule markers above the diagonal (or regression line) indicate bona fide structure rather than ambient RNA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "from numpy.linalg import lstsq\n",
        "from scipy.spatial import cKDTree\n",
        "from scipy.stats import wilcoxon\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sc.settings.verbosity = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = \"MERSCOPE_WT_1\"\n",
        "data_path = f\"../../data/{dataset}/\"\n",
        "output_path = f\"../../output/{dataset}/\"\n",
        "benchmark_path = \"../../output/benchmark/benchmark_diffusion/\"\n",
        "\n",
        "transcripts_path = data_path + \"processed_data/transcripts.parquet\"\n",
        "granules_path = output_path + \"all_granules.parquet\"\n",
        "spots_path = data_path + \"processed_data/spots.h5ad\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load data and filter granules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# overlaps_nucleus = 1 means in soma\n",
        "transcripts = pd.read_parquet(transcripts_path)\n",
        "print(f\"Transcripts: {len(transcripts)}\")\n",
        "print(f\"Transcript columns: {list(transcripts.columns)}\")\n",
        "\n",
        "spots = sc.read_h5ad(spots_path)\n",
        "print(f\"Spots: {spots.n_obs}\")\n",
        "print(f\"Spot obs columns: {list(spots.obs.columns)}\")\n",
        "\n",
        "granules = pd.read_parquet(granules_path)\n",
        "print(f\"All granules (raw): {len(granules)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter: sphere_r <= 4, in_soma_ratio <= 0.1, nc_ratio <= 0.1\n",
        "granules = granules[granules[\"sphere_r\"] <= 4].copy().reset_index(drop=True)\n",
        "nc_genes_df = pd.read_csv(data_path + \"processed_data/negative_controls.csv\")\n",
        "nc_genes = list(nc_genes_df[\"Gene\"])\n",
        "\n",
        "def make_tree_3d(d1, d2, d3):\n",
        "    points = np.c_[np.ravel(d1), np.ravel(d2), np.ravel(d3)]\n",
        "    return cKDTree(points)\n",
        "\n",
        "def compute_nc_ratio(granules_df, transcripts_df, nc_genes_list):\n",
        "    nc_transcripts = transcripts_df[transcripts_df[\"target\"].isin(nc_genes_list)]\n",
        "    if nc_transcripts.shape[0] == 0:\n",
        "        return np.zeros(len(granules_df))\n",
        "    z_col = \"sphere_z\" if \"sphere_z\" in granules_df.columns else \"layer_z\"\n",
        "    tree = make_tree_3d(\n",
        "        np.array(nc_transcripts[\"global_x\"]),\n",
        "        np.array(nc_transcripts[\"global_y\"]),\n",
        "        np.array(nc_transcripts[\"global_z\"]),\n",
        "    )\n",
        "    centers = granules_df[[\"sphere_x\", \"sphere_y\", z_col]].to_numpy()\n",
        "    radii = granules_df[\"sphere_r\"].to_numpy()\n",
        "    sizes = granules_df[\"size\"].to_numpy().astype(float)\n",
        "    counts = np.array([len(tree.query_ball_point(c, r)) for c, r in zip(centers, radii)])\n",
        "    nc_ratio = np.where(sizes > 0, counts / sizes, 0.0)\n",
        "    return nc_ratio\n",
        "\n",
        "nc_ratio = compute_nc_ratio(granules, transcripts, nc_genes)\n",
        "granules = granules.copy()\n",
        "granules[\"nc_ratio\"] = nc_ratio\n",
        "\n",
        "granules = granules[granules[\"in_soma_ratio\"] <= 0.1].copy()\n",
        "granules = granules[(granules[\"nc_ratio\"] == 0) | (granules[\"nc_ratio\"] < 0.1)].copy().reset_index(drop=True)\n",
        "\n",
        "print(f\"True RNA granules (after all filters): {len(granules)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Map transcripts to spots and build soma/extrasomatic pseudo counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Map transcripts to 50x50 spot squares [sx-25, sx+25) x [sy-25, sy+25)\n",
        "GRID_LEN = 50\n",
        "HALF_LEN = GRID_LEN / 2\n",
        "\n",
        "spot_x = spots.obs[\"global_x\"].values\n",
        "spot_y = spots.obs[\"global_y\"].values\n",
        "tx_x = transcripts[\"global_x\"].values\n",
        "tx_y = transcripts[\"global_y\"].values\n",
        "\n",
        "spot_idx = np.full(len(transcripts), -1, dtype=np.int64)\n",
        "for i in range(len(spot_x)):\n",
        "    in_spot = (\n",
        "        (tx_x >= spot_x[i] - HALF_LEN) & (tx_x < spot_x[i] + HALF_LEN) &\n",
        "        (tx_y >= spot_y[i] - HALF_LEN) & (tx_y < spot_y[i] + HALF_LEN)\n",
        "    )\n",
        "    spot_idx[in_spot] = i\n",
        "\n",
        "transcripts[\"spot_idx\"] = spot_idx\n",
        "n_assigned = (spot_idx >= 0).sum()\n",
        "print(f\"Transcripts in spot squares: {n_assigned} / {len(transcripts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genes_df = pd.read_csv(data_path + \"processed_data/genes.csv\")\n",
        "gene_col = genes_df.columns[0]  # typically \"genes\"\n",
        "genes_all = list(genes_df[gene_col].dropna().unique())\n",
        "print(f\"Genes from genes.csv: {len(genes_all)}\")\n",
        "\n",
        "in_soma_col = \"overlaps_nucleus\"  # 1 = in soma, 0 = extrasomatic\n",
        "if in_soma_col not in transcripts.columns:\n",
        "    raise KeyError(f\"Transcripts must have '{in_soma_col}' column\")\n",
        "\n",
        "trans_in_spots = transcripts[transcripts[\"spot_idx\"] >= 0].copy()\n",
        "trans_in_spots[\"in_soma\"] = (trans_in_spots[in_soma_col] == 1).astype(int)\n",
        "trans_in_spots[\"extra\"] = 1 - trans_in_spots[\"in_soma\"]\n",
        "\n",
        "counts_soma = trans_in_spots.groupby([\"spot_idx\", \"target\"])[\"in_soma\"].sum().unstack(fill_value=0)\n",
        "counts_extra = trans_in_spots.groupby([\"spot_idx\", \"target\"])[\"extra\"].sum().unstack(fill_value=0)\n",
        "\n",
        "# Use genes from genes.csv; fill 0 for genes with no counts\n",
        "counts_soma = counts_soma.reindex(columns=genes_all, fill_value=0)\n",
        "counts_extra = counts_extra.reindex(columns=genes_all, fill_value=0)\n",
        "\n",
        "print(f\"Genes: {len(genes_all)}, Spots with counts: {counts_soma.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Baseline logFC (extrasomatic vs somatic)\n",
        "\n",
        "Composition-based: log2(frac_extra/frac_soma). P-value from spot-level paired Wilcoxon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_soma = transcripts[in_soma_col] == 1\n",
        "mask_extra = transcripts[in_soma_col] != 1\n",
        "total_soma = mask_soma.sum()\n",
        "total_extra = mask_extra.sum()\n",
        "\n",
        "eps = 0.5\n",
        "baseline_logFC = []\n",
        "baseline_pval_paired = []  # keep spot-level p-value for significance\n",
        "for g in genes_all:\n",
        "    mask_g = transcripts[\"target\"] == g\n",
        "    count_soma_g = (mask_g & mask_soma).sum()\n",
        "    count_extra_g = (mask_g & mask_extra).sum()\n",
        "    frac_soma = (count_soma_g + eps) / (total_soma + eps)\n",
        "    frac_extra = (count_extra_g + eps) / (total_extra + eps)\n",
        "    logfc = np.log2(frac_extra) - np.log2(frac_soma)\n",
        "    baseline_logFC.append(logfc)\n",
        "    s = counts_soma[g].values + 1.0\n",
        "    e = counts_extra[g].values + 1.0\n",
        "    try:\n",
        "        stat, p = wilcoxon(e, s, alternative=\"two-sided\")\n",
        "        baseline_pval_paired.append(p)\n",
        "    except Exception:\n",
        "        baseline_pval_paired.append(1.0)\n",
        "\n",
        "baseline_df = pd.DataFrame({\n",
        "    \"gene\": genes_all,\n",
        "    \"baseline_logFC\": baseline_logFC,\n",
        "    \"baseline_pval\": baseline_pval_paired,\n",
        "})\n",
        "print(baseline_df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Granule enrichment statistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z_col = \"layer_z\"\n",
        "tx_xyz = transcripts[[\"global_x\", \"global_y\", \"global_z\"]].to_numpy(dtype=np.float64)\n",
        "tree_tx = cKDTree(tx_xyz)\n",
        "\n",
        "in_granule = np.zeros(len(transcripts), dtype=np.int8)\n",
        "gnl_centers = granules[[\"sphere_x\", \"sphere_y\", z_col]].to_numpy(dtype=np.float64)\n",
        "gnl_radii = granules[\"sphere_r\"].to_numpy(dtype=np.float64)\n",
        "\n",
        "for i in range(len(granules)):\n",
        "    idx = tree_tx.query_ball_point(gnl_centers[i], gnl_radii[i] + 0.1)\n",
        "    if len(idx) > 0:\n",
        "        in_granule[idx] = 1\n",
        "\n",
        "transcripts[\"in_granule\"] = in_granule\n",
        "print(f\"Transcripts in granules: {in_granule.sum()} / {len(transcripts)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask_extra = transcripts[in_soma_col] != 1\n",
        "mask_in_gnl_extra = (transcripts[\"in_granule\"] == 1) & mask_extra\n",
        "mask_non_gnl_extra = (transcripts[\"in_granule\"] == 0) & mask_extra\n",
        "total_tx_in_gnl_extra = mask_in_gnl_extra.sum()\n",
        "total_tx_non_gnl_extra = mask_non_gnl_extra.sum()\n",
        "\n",
        "granule_enrichment = []\n",
        "eps = 0.5\n",
        "for idx, g in enumerate(genes_all):\n",
        "    mask_g = transcripts[\"target\"] == g\n",
        "    in_gnl_extra_g = (mask_in_gnl_extra & mask_g).sum()\n",
        "    non_gnl_extra_g = (mask_non_gnl_extra & mask_g).sum()\n",
        "    frac_gnl = (in_gnl_extra_g + eps) / (total_tx_in_gnl_extra + eps)\n",
        "    frac_non = (non_gnl_extra_g + eps) / (total_tx_non_gnl_extra + eps)\n",
        "    enr = np.log2(frac_gnl) - np.log2(frac_non)\n",
        "    granule_enrichment.append(enr)\n",
        "\n",
        "enrichment_df = pd.DataFrame({\"gene\": genes_all, \"granule_enrichment\": granule_enrichment})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "granule_markers = ['Syn1', 'Cyfip2', 'Vamp2', 'Bsn', 'Stx1a', 'Map2', 'Nfasc', 'Slc17a7', 'Gria1', 'Map1a', 'Ddn', 'Gap43', 'Mapt', 'Gphn', 'Homer2', 'Slc17a6', 'Dlg3', 'Nlgn2', 'Gria2', 'Nlgn1', 'Nav1', 'Slc32a1', 'Tubb3', 'Dlg4', 'Syt1', 'Camk2a', 'Nrxn1', 'Syp', 'Nlgn3', 'Cplx2', 'Ank3', 'Shank1', 'Homer1', 'Shank3']\n",
        "\n",
        "plot_df = baseline_df.merge(enrichment_df, on=\"gene\", how=\"inner\")\n",
        "plot_df_markers = plot_df[plot_df[\"gene\"].isin(granule_markers)].copy()\n",
        "\n",
        "print(f\"Genes in plot: {len(plot_df)}, Markers: {len(plot_df_markers)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative: granule enrichment vs soma\n",
        "\n",
        "Set `USE_ALT_GRANULE_VS_SOMA = True` to use log2(frac_in_granules/frac_soma). Other options: minimum count filter, larger pseudocount."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: alternative granule enrichment = \"vs soma\" (same reference as baseline)\n",
        "# This often puts more markers above the diagonal: granules vs soma >= extrasomatic vs soma for true markers.\n",
        "USE_ALT_GRANULE_VS_SOMA = False  # Set True to use this definition and replot\n",
        "if USE_ALT_GRANULE_VS_SOMA:\n",
        "    total_soma = (transcripts[in_soma_col] == 1).sum()\n",
        "    total_in_gnl = (transcripts[\"in_granule\"] == 1).sum()\n",
        "    granule_enrichment_alt = []\n",
        "    eps = 0.5\n",
        "    for g in genes_all:\n",
        "        mask_g = transcripts[\"target\"] == g\n",
        "        in_gnl_g = ((transcripts[\"in_granule\"] == 1) & mask_g).sum()\n",
        "        soma_g = ((transcripts[in_soma_col] == 1) & mask_g).sum()\n",
        "        frac_soma = (soma_g + eps) / (total_soma + eps)\n",
        "        frac_gnl = (in_gnl_g + eps) / (total_in_gnl + eps)\n",
        "        granule_enrichment_alt.append(np.log2(frac_gnl) - np.log2(frac_soma))\n",
        "    plot_df[\"granule_enrichment_alt\"] = granule_enrichment_alt\n",
        "    plot_df[\"granule_enrichment\"] = plot_df[\"granule_enrichment_alt\"]\n",
        "    print(\"Using alternative granule enrichment (vs soma). Re-run the next cell (Excess Δ and regression) and below.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Excess statistic (Δ) and regression reference\n",
        "\n",
        "Δ = granule_enrichment − baseline_logFC. Regression on non-markers yields a reference line; markers above it are enriched beyond what baseline predicts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Excess statistic\n",
        "plot_df[\"delta\"] = plot_df[\"granule_enrichment\"] - plot_df[\"baseline_logFC\"]\n",
        "\n",
        "# Regression on non-markers: granule_enrichment ~ baseline_logFC\n",
        "non_marker = ~plot_df[\"gene\"].isin(granule_markers)\n",
        "X = plot_df.loc[non_marker, \"baseline_logFC\"].values.reshape(-1, 1)\n",
        "y = plot_df.loc[non_marker, \"granule_enrichment\"].values\n",
        "# Linear regression: y = slope * x + intercept\n",
        "ones = np.ones((len(X), 1))\n",
        "X_aug = np.hstack([X, ones])\n",
        "coef, _, _, _ = lstsq(X_aug, y, rcond=None)\n",
        "reg_slope, reg_intercept = coef[0], coef[1]\n",
        "plot_df[\"expected_ge\"] = reg_slope * plot_df[\"baseline_logFC\"] + reg_intercept\n",
        "plot_df[\"above_regression\"] = plot_df[\"granule_enrichment\"] > plot_df[\"expected_ge\"]\n",
        "\n",
        "# Re-derive plot_df_markers so it includes the new columns (delta, above_regression, expected_ge)\n",
        "plot_df_markers = plot_df[plot_df[\"gene\"].isin(granule_markers)].copy()\n",
        "\n",
        "# Count markers above diagonal vs above regression line\n",
        "above_diag = (plot_df_markers[\"granule_enrichment\"] > plot_df_markers[\"baseline_logFC\"]).sum()\n",
        "above_reg = plot_df_markers[\"above_regression\"].sum()\n",
        "print(f\"Regression (non-markers): granule_enrichment = {reg_slope:.4f} * baseline_logFC + {reg_intercept:.4f}\")\n",
        "print(f\"Granule markers above diagonal (y=x): {above_diag} / {len(plot_df_markers)}\")\n",
        "print(f\"Granule markers above regression line: {above_reg} / {len(plot_df_markers)}\")\n",
        "plot_df.to_csv(benchmark_path + \"benchmark_diffusion_df.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mcDETECT-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
