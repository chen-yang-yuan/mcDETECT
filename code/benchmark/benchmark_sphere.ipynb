{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Benchmark sphere radius for profile()\n",
        "\n",
        "Benchmark how the choice of sphere radius (used to gather transcripts and build granule expression profiles) affects per-granule metrics. Uses fine detection results exported as `granules.parquet`.\n",
        "\n",
        "**Four radius settings:**\n",
        "1. **Default**: granule-specific radius (as in mcDETECT `profile()`, no buffer)\n",
        "2. **Fixed**: same radius for all granules = median of granule radii\n",
        "3. **Expand**: current radius × 1.2 per granule\n",
        "4. **Shrink**: current radius × 0.8 per granule\n",
        "\n",
        "**Per-granule metrics (for each setting):**\n",
        "- Number of transcripts per granule\n",
        "- Number of unique genes per granule\n",
        "- Negative-control ratio (NC transcripts / granule-marker transcripts in sphere)\n",
        "- In-soma ratio (granule-marker transcripts in sphere that overlap soma / all granule-marker transcripts in sphere)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = \"MERSCOPE_WT_1\"\n",
        "data_path = f\"../../data/{dataset}/\"\n",
        "output_path = f\"../../output/{dataset}/\"\n",
        "benchmark_path = \"../../output/benchmark/benchmark_sphere/\"\n",
        "representative_dir = os.path.join(benchmark_path, f\"{dataset}_representative_data\")\n",
        "os.makedirs(benchmark_path, exist_ok=True)\n",
        "os.makedirs(representative_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fine detection results (with filtering applied)\n",
        "granules = pd.read_parquet(output_path + \"granules.parquet\")\n",
        "print(f\"Granules: {len(granules)}\")\n",
        "\n",
        "transcripts = pd.read_parquet(data_path + \"processed_data/transcripts.parquet\")\n",
        "if \"target\" not in transcripts.columns and \"gene\" in transcripts.columns:\n",
        "    transcripts[\"target\"] = transcripts[\"gene\"]\n",
        "\n",
        "genes = pd.read_csv(data_path + \"processed_data/genes.csv\")\n",
        "genes = list(genes.iloc[:, 0])\n",
        "\n",
        "nc_genes = list(pd.read_csv(data_path + \"processed_data/negative_controls.csv\")[\"Gene\"])\n",
        "gnl_genes = [\"Camk2a\", \"Cplx2\", \"Slc17a7\", \"Ddn\", \"Syp\", \"Map1a\", \"Shank1\", \"Syn1\", \"Gria1\", \"Gria2\", \"Cyfip2\", \"Vamp2\", \"Bsn\", \"Slc32a1\", \"Nfasc\", \"Syt1\", \"Tubb3\", \"Nav1\", \"Shank3\", \"Mapt\"]\n",
        "\n",
        "if \"overlaps_nucleus\" not in transcripts.columns and \"overlaps_nucleus_5_dilation\" in transcripts.columns:\n",
        "    transcripts[\"overlaps_nucleus\"] = transcripts[\"overlaps_nucleus_5_dilation\"]\n",
        "if \"layer_z\" not in granules.columns and \"sphere_z\" in granules.columns:\n",
        "    granules[\"layer_z\"] = granules[\"sphere_z\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper functions\n",
        "\n",
        "Center for each sphere uses `(sphere_x, sphere_y, layer_z)` to match mcDETECT's `profile()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_tree_3d(d1, d2, d3):\n",
        "    \"\"\"Build 3D cKDTree from coordinate arrays.\"\"\"\n",
        "    points = np.c_[np.ravel(d1), np.ravel(d2), np.ravel(d3)]\n",
        "    return cKDTree(points)\n",
        "\n",
        "\n",
        "def get_radii(granules, setting):\n",
        "    \"\"\"Return array of radii for each granule. setting in {'default', 'fixed', 'expand', 'shrink'}.\"\"\"\n",
        "    r = granules[\"sphere_r\"].to_numpy()\n",
        "    if setting == \"default\":\n",
        "        return r.copy()\n",
        "    if setting == \"fixed\":\n",
        "        med = np.median(r)\n",
        "        return np.full(len(granules), med)\n",
        "    if setting == \"expand\":\n",
        "        return r * 1.2\n",
        "    if setting == \"shrink\":\n",
        "        return r * 0.8\n",
        "    raise ValueError(f\"Unknown setting: {setting}\")\n",
        "\n",
        "\n",
        "def compute_per_granule_metrics(granules, transcripts, radii, gnl_genes, nc_genes):\n",
        "    \"\"\"\n",
        "    For each granule with center (sphere_x, sphere_y, layer_z) and radius from `radii`,\n",
        "    compute: n_transcripts, n_unique_genes, nc_ratio, in_soma_ratio.\n",
        "    nc_ratio = (NC transcript count in sphere) / (granule-marker transcript count in sphere).\n",
        "    in_soma_ratio = (granule-marker transcripts in sphere that overlap soma) / (granule-marker transcripts in sphere).\n",
        "    query_ball_point returns iloc indices; we use numpy arrays for correct indexing.\n",
        "    \"\"\"\n",
        "    tree = make_tree_3d(\n",
        "        transcripts[\"global_x\"].to_numpy(),\n",
        "        transcripts[\"global_y\"].to_numpy(),\n",
        "        transcripts[\"global_z\"].to_numpy(),\n",
        "    )\n",
        "    centers = granules[[\"sphere_x\", \"sphere_y\", \"layer_z\"]].to_numpy()\n",
        "    target_arr = transcripts[\"target\"].to_numpy()\n",
        "    overlaps_arr = transcripts[\"overlaps_nucleus\"].to_numpy() if \"overlaps_nucleus\" in transcripts.columns else np.zeros(len(transcripts))\n",
        "\n",
        "    n_transcripts = []\n",
        "    n_unique_genes = []\n",
        "    nc_ratios = []\n",
        "    in_soma_ratios = []\n",
        "\n",
        "    for i in range(len(granules)):\n",
        "        c, r = centers[i], radii[i]\n",
        "        idx = tree.query_ball_point(c, r)\n",
        "        if not idx:\n",
        "            n_transcripts.append(0)\n",
        "            n_unique_genes.append(0)\n",
        "            nc_ratios.append(0.0)\n",
        "            in_soma_ratios.append(np.nan)\n",
        "            continue\n",
        "        idx = np.asarray(idx)\n",
        "        n_transcripts.append(len(idx))\n",
        "        n_unique_genes.append(len(np.unique(target_arr[idx])))\n",
        "\n",
        "        gnl_mask = np.isin(target_arr[idx], gnl_genes)\n",
        "        nc_mask = np.isin(target_arr[idx], nc_genes)\n",
        "        gnl_count = gnl_mask.sum()\n",
        "        nc_count = nc_mask.sum()\n",
        "        nc_ratios.append(nc_count / gnl_count if gnl_count > 0 else 0.0)\n",
        "\n",
        "        if gnl_count == 0:\n",
        "            in_soma_ratios.append(np.nan)\n",
        "        else:\n",
        "            gnl_iloc = idx[gnl_mask]\n",
        "            in_soma = overlaps_arr[gnl_iloc].sum()\n",
        "            in_soma_ratios.append(in_soma / gnl_count)\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        \"n_transcripts\": n_transcripts,\n",
        "        \"n_unique_genes\": n_unique_genes,\n",
        "        \"nc_ratio\": nc_ratios,\n",
        "        \"in_soma_ratio\": in_soma_ratios,\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all four radius settings and compute per-granule metrics\n",
        "settings = [\"default\", \"fixed\", \"expand\", \"shrink\"]\n",
        "results = {}\n",
        "\n",
        "for s in settings:\n",
        "    radii = get_radii(granules, s)\n",
        "    df = compute_per_granule_metrics(granules, transcripts, radii, gnl_genes, nc_genes)\n",
        "    results[s] = df\n",
        "    print(f\"Done: {s}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: per-setting aggregates\n",
        "\n",
        "For each radius setting, report (across granules): mean and median of n_transcripts, n_unique_genes, nc_ratio, and in_soma_ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summary_row(name, df):\n",
        "    return {\n",
        "        \"setting\": name,\n",
        "        \"mean_n_transcripts\": df[\"n_transcripts\"].mean(),\n",
        "        \"median_n_transcripts\": df[\"n_transcripts\"].median(),\n",
        "        \"mean_n_unique_genes\": df[\"n_unique_genes\"].mean(),\n",
        "        \"median_n_unique_genes\": df[\"n_unique_genes\"].median(),\n",
        "        \"mean_nc_ratio\": df[\"nc_ratio\"].mean(),\n",
        "        \"median_nc_ratio\": df[\"nc_ratio\"].median(),\n",
        "        \"mean_in_soma_ratio\": df[\"in_soma_ratio\"].mean(),\n",
        "        \"median_in_soma_ratio\": df[\"in_soma_ratio\"].median(),\n",
        "    }\n",
        "\n",
        "summary_rows = [summary_row(s, results[s]) for s in settings]\n",
        "summary_df = pd.DataFrame(summary_rows)\n",
        "summary_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save summary and per-granule metrics for each setting\n",
        "summary_df.to_csv(benchmark_path + \"benchmark_sphere_summary.csv\", index=False)\n",
        "for s in settings:\n",
        "    out = results[s].copy()\n",
        "    out[\"setting\"] = s\n",
        "    out.to_csv(benchmark_path + f\"benchmark_sphere_metrics_{s}.csv\", index=False)\n",
        "print(\"Saved benchmark_sphere_summary.csv and benchmark_sphere_metrics_<setting>.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gene expression similarity within spheres across settings\n",
        "\n",
        "For each gene, each setting yields an expression vector across the same spheres (granules). We compute the Pearson correlation between the default setting and each of the other three (fixed, expand, shrink) per gene, then plot a correlation heatmap: rows = genes, columns = default vs fixed / default vs expand / default vs shrink."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_expression_matrix(granules, transcripts, radii, genes):\n",
        "    \"\"\"Return (n_granules x n_genes) dense array of transcript counts per sphere, matching profile() logic.\"\"\"\n",
        "    trans = transcripts[transcripts[\"target\"].isin(genes)].copy()\n",
        "    if trans.shape[0] == 0:\n",
        "        return np.zeros((len(granules), len(genes)))\n",
        "    tree = make_tree_3d(\n",
        "        trans[\"global_x\"].to_numpy(),\n",
        "        trans[\"global_y\"].to_numpy(),\n",
        "        trans[\"global_z\"].to_numpy(),\n",
        "    )\n",
        "    gene_to_idx = {g: i for i, g in enumerate(genes)}\n",
        "    target_arr = trans[\"target\"].to_numpy()\n",
        "    centers = granules[[\"sphere_x\", \"sphere_y\", \"layer_z\"]].to_numpy()\n",
        "    n_gnl, n_gene = len(granules), len(genes)\n",
        "    X = np.zeros((n_gnl, n_gene), dtype=np.float32)\n",
        "    for i in range(n_gnl):\n",
        "        idx = tree.query_ball_point(centers[i], radii[i])\n",
        "        if not idx:\n",
        "            continue\n",
        "        idx = np.asarray(idx)\n",
        "        counts = Counter(target_arr[idx])\n",
        "        for g, c in counts.items():\n",
        "            X[i, gene_to_idx[g]] = c\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build expression matrix (n_granules x n_genes) for each setting\n",
        "print(\"Building expression matrices...\")\n",
        "X_default = build_expression_matrix(granules, transcripts, get_radii(granules, \"default\"), genes)\n",
        "X_fixed   = build_expression_matrix(granules, transcripts, get_radii(granules, \"fixed\"), genes)\n",
        "X_expand  = build_expression_matrix(granules, transcripts, get_radii(granules, \"expand\"), genes)\n",
        "X_shrink  = build_expression_matrix(granules, transcripts, get_radii(granules, \"shrink\"), genes)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write granule expression profiles (with metadata) as h5ad for each radius setting\n",
        "import anndata\n",
        "\n",
        "def expression_to_adata(X, granules, genes, setting_name):\n",
        "    \"\"\"Build AnnData: X = expression (n_granules x n_genes), obs = granule metadata including coordinates.\"\"\"\n",
        "    obs = granules.copy()\n",
        "    obs[\"granule_id\"] = [f\"gnl_{i}\" for i in range(len(granules))]\n",
        "    obs = obs.astype({\"granule_id\": str})\n",
        "    obs.rename(columns={\"sphere_x\": \"global_x\", \"sphere_y\": \"global_y\", \"sphere_z\": \"global_z\"}, inplace=True)\n",
        "    adata = anndata.AnnData(X=X.astype(np.float32), obs=obs)\n",
        "    adata.var[\"genes\"] = genes\n",
        "    adata.var_names = genes\n",
        "    adata.var_names_make_unique()\n",
        "    adata.obs[\"radius_setting\"] = setting_name\n",
        "    return adata\n",
        "\n",
        "for name, X in [\n",
        "    (\"default\", X_default),\n",
        "    (\"fixed\", X_fixed),\n",
        "    (\"expand\", X_expand),\n",
        "    (\"shrink\", X_shrink),\n",
        "]:\n",
        "    adata = expression_to_adata(X, granules, genes, name)\n",
        "    out_path = os.path.join(representative_dir, f\"granules_expression_{name}.h5ad\")\n",
        "    adata.write_h5ad(out_path)\n",
        "    print(f\"Wrote {out_path} ({adata.n_obs} granules x {adata.n_vars} genes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Per-gene correlation: default vs each other setting (expression vector across spheres)\n",
        "n_genes = len(genes)\n",
        "corr_vs_fixed  = np.array([np.corrcoef(X_default[:, g], X_fixed[:, g])[0, 1]   for g in range(n_genes)])\n",
        "corr_vs_expand = np.array([np.corrcoef(X_default[:, g], X_expand[:, g])[0, 1] for g in range(n_genes)])\n",
        "corr_vs_shrink = np.array([np.corrcoef(X_default[:, g], X_shrink[:, g])[0, 1] for g in range(n_genes)])\n",
        "# Constant vectors yield nan; replace with 1.0 (perfect correlation with self)\n",
        "corr_vs_fixed  = np.nan_to_num(corr_vs_fixed,  nan=1.0, posinf=1.0, neginf=-1.0)\n",
        "corr_vs_expand = np.nan_to_num(corr_vs_expand, nan=1.0, posinf=1.0, neginf=-1.0)\n",
        "corr_vs_shrink = np.nan_to_num(corr_vs_shrink, nan=1.0, posinf=1.0, neginf=-1.0)\n",
        "corr_matrix = np.column_stack([corr_vs_fixed, corr_vs_expand, corr_vs_shrink])  # (n_genes, 3)\n",
        "corr_df = pd.DataFrame(corr_matrix, index=genes, columns=[\"default vs fixed\", \"default vs expand\", \"default vs shrink\"])\n",
        "corr_df.to_csv(benchmark_path + \"benchmark_sphere_expression_correlation.csv\")\n",
        "corr_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "# # fig, ax = plt.subplots(figsize=(4, max(6, len(genes) * 0.04)))\n",
        "# # sns.heatmap(corr_df, ax=ax, cmap=\"RdYlBu_r\", vmin=0, vmax=1, cbar_kws={\"label\": \"Pearson r\"})\n",
        "# # ax.set_xlabel(\"Default vs other setting\")\n",
        "# # ax.set_ylabel(\"Gene\")\n",
        "# # plt.tight_layout()\n",
        "# # plt.savefig(benchmark_path + \"benchmark_sphere_expression_correlation_heatmap.jpeg\", dpi=500, bbox_inches=\"tight\")\n",
        "# # plt.close()\n",
        "\n",
        "# fig, ax = plt.subplots(figsize=(15, 5))\n",
        "# hm = sns.heatmap(corr_df.T, ax=ax, cmap=\"RdYlBu_r\", vmin=0, vmax=1, cbar_kws={ \"orientation\": \"horizontal\", \"label\": \"Pearson r\", \"pad\": 0.25, \"shrink\": 0.5, \"aspect\": 30})\n",
        "# ax.set_xlabel(\" \")\n",
        "# ax.set_ylabel(\" \")\n",
        "# # Ensure colorbar label & ticks are below\n",
        "# cbar = hm.collections[0].colorbar\n",
        "# cbar.ax.xaxis.set_label_position(\"bottom\")\n",
        "# cbar.ax.xaxis.tick_bottom()\n",
        "# plt.tight_layout()\n",
        "# plt.savefig(benchmark_path + \"benchmark_sphere_expression_correlation_heatmap.jpeg\", dpi=500, bbox_inches=\"tight\")\n",
        "# plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gene-by-gene correlation heatmaps (default vs others)\n",
        "\n",
        "Three heatmaps: rows = genes (expression from **default** setting across spheres), columns = genes (expression from **other** setting). Entry (i, j) = Pearson r between default gene *i* and other-setting gene *j*. One heatmap each for default vs fixed, default vs expand, default vs shrink."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Gene-by-gene correlation: rows = default (gene i), columns = other setting (gene j); entry = corr(default_i, other_j)\n",
        "# # Vectorized: stack [X_default, X_other], then corrcoef(.T) gives block matrix; top-right block = default vs other\n",
        "# def gene_gene_corr_default_vs_other(X_default, X_other, genes):\n",
        "#     n = len(genes)\n",
        "#     M = np.hstack([X_default, X_other])  # (n_granules, 2*n_genes)\n",
        "#     R = np.corrcoef(M.T)                  # (2*n_genes, 2*n_genes)\n",
        "#     C = R[:n, n:]                         # (n_genes, n_genes): default rows, other cols\n",
        "#     C = np.nan_to_num(C, nan=0.0, posinf=1.0, neginf=-1.0)\n",
        "#     return pd.DataFrame(C, index=genes, columns=genes)\n",
        "\n",
        "# gene_corr_default_fixed  = gene_gene_corr_default_vs_other(X_default, X_fixed, genes)\n",
        "# gene_corr_default_expand = gene_gene_corr_default_vs_other(X_default, X_expand, genes)\n",
        "# gene_corr_default_shrink = gene_gene_corr_default_vs_other(X_default, X_shrink, genes)\n",
        "\n",
        "# for corr_df, title, suffix in [\n",
        "#     (gene_corr_default_fixed, \"default vs fixed\", \"default_vs_fixed\"),\n",
        "#     (gene_corr_default_expand, \"default vs expand\", \"default_vs_expand\"),\n",
        "#     (gene_corr_default_shrink, \"default vs shrink\", \"default_vs_shrink\"),\n",
        "# ]:\n",
        "#     fig, ax = plt.subplots(figsize=(12, 12))\n",
        "#     sns.heatmap(corr_df, ax=ax, cmap=\"RdYlBu_r\", vmin=-1, vmax=1, center=0,\n",
        "#                 square=True, cbar_kws={\"label\": \"Pearson r\"})\n",
        "#     ax.set_title(title)\n",
        "#     ax.set_xlabel(\"Gene (other setting)\")\n",
        "#     ax.set_ylabel(\"Gene (default)\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(benchmark_path + f\"benchmark_sphere_gene_gene_correlation_heatmap_{suffix}.jpeg\", dpi=300, bbox_inches=\"tight\")\n",
        "#     plt.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mcDETECT-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
