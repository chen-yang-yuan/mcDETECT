{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granule subtyping for paired WT and AD benchmark samples\n",
    "\n",
    "This notebook completes granule subtyping and annotation for paired WT and AD samples across benchmark settings (benchmark_rho, benchmark_filtering, benchmark_sphere, etc.). For each setting with both `MERSCOPE_WT_1_representative_data` and `MERSCOPE_AD_1_representative_data`, we:\n",
    "1. Load or build granule expression profiles and concatenate WT + AD into one anndata.\n",
    "2. Subtype granules (manual: k-means + heatmap → blank annotation; automatic: GranuleSubtyper with tuning steps).\n",
    "3. Export subtype labels and subtype density per brain region per sample to `output/benchmark/benchmark_{xxx}/WT_AD_comparison/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from mcDETECT.utils import *\n",
    "from mcDETECT.model import mcDETECT\n",
    "from mcDETECT.downstream import spot_granule, classify_granules\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single seed for all randomness (k-means, etc.)\n",
    "SEED = 0\n",
    "\n",
    "# Benchmark root: output/benchmark/\n",
    "BENCHMARK_ROOT = \"../../output/benchmark/\"\n",
    "\n",
    "# Data paths for WT and AD (for transcripts, genes, spots when building profiles or computing density)\n",
    "DATA_PATH_WT = \"../../data/MERSCOPE_WT_1/\"\n",
    "DATA_PATH_AD = \"../../data/MERSCOPE_AD_1/\"\n",
    "\n",
    "# Folder names for representative data under each benchmark_xxx\n",
    "WT_REPR_DIR = \"MERSCOPE_WT_1_representative_data\"\n",
    "AD_REPR_DIR = \"MERSCOPE_AD_1_representative_data\"\n",
    "\n",
    "# Output subfolder under each benchmark_xxx for labels and density\n",
    "COMPARISON_DIR = \"WT_AD_comparison\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 34 granule markers (same as current notebook)\n",
    "marker_genes = {\"pre-syn\": [\"Bsn\", \"Gap43\", \"Nrxn1\", \"Slc17a6\", \"Slc17a7\", \"Slc32a1\", \"Snap25\", \"Stx1a\", \"Syn1\", \"Syp\", \"Syt1\", \"Vamp2\", \"Cplx2\"],\n",
    "                \"post-syn\": [\"Camk2a\", \"Dlg3\", \"Dlg4\", \"Gphn\", \"Gria1\", \"Gria2\", \"Homer1\", \"Homer2\", \"Nlgn1\", \"Nlgn2\", \"Nlgn3\", \"Shank1\", \"Shank3\"],\n",
    "                \"axons\": [\"Ank3\", \"Nav1\", \"Sptnb4\", \"Nfasc\", \"Mapt\", \"Tubb3\"],\n",
    "                \"dendrites\": [\"Actb\", \"Cyfip2\", \"Ddn\", \"Dlg4\", \"Map1a\", \"Map2\"]}\n",
    "ref_genes = list(set(marker_genes[\"pre-syn\"] + marker_genes[\"post-syn\"] + marker_genes[\"axons\"] + marker_genes[\"dendrites\"]))\n",
    "print(f\"Number of unique marker genes: {len(ref_genes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit list of benchmark settings (WT and AD share the same filename per setting)\n",
    "\n",
    "Under each benchmark (benchmark_rho, benchmark_filtering, benchmark_sphere), WT and AD outputs are stored in\n",
    "`MERSCOPE_WT_1_representative_data/` and `MERSCOPE_AD_1_representative_data/` with **the same filename** for a given parameter setting.\n",
    "Format is inferred from extension: `.parquet` → granules, build profile via mc.profile(); `.h5ad` → expression profile, load directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (benchmark_name, filename) — same filename in WT and AD folders for each setting.\n",
    "# Parquet = granules → profile(); h5ad = expression profile → load as-is.\n",
    "BENCHMARK_SETTINGS = [\n",
    "    # benchmark_rho: representative rho values (parquet)\n",
    "    (\"benchmark_rho\", \"granules_rho_0.0.parquet\"),\n",
    "    (\"benchmark_rho\", \"granules_rho_0.2.parquet\"),\n",
    "    (\"benchmark_rho\", \"granules_rho_0.5.parquet\"),\n",
    "    (\"benchmark_rho\", \"granules_rho_0.8.parquet\"),\n",
    "    # benchmark_filtering: inSomaThr and ncThr (parquet)\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr1.0_ncThr1.0.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr0.1_ncThr1.0.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr1.0_ncThr0.1.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr0.1_ncThr0.1.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr0.05_ncThr0.1.parquet\"),\n",
    "    # benchmark_sphere: radius setting (h5ad = expression profile)\n",
    "    (\"benchmark_sphere\", \"granules_expression_default.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_fixed.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_expand.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_shrink.h5ad\"),\n",
    "]\n",
    "print(f\"Total settings: {len(BENCHMARK_SETTINGS)}\")\n",
    "for bench, fname in BENCHMARK_SETTINGS:\n",
    "    fmt = \"parquet (build profile)\" if fname.endswith(\".parquet\") else \"h5ad (load)\"\n",
    "    print(f\"  {bench} / {fname}  [{fmt}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load one file per sample (same filename in WT and AD) and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genes_and_transcripts(data_path):\n",
    "    genes_df = pd.read_csv(os.path.join(data_path, \"processed_data/genes.csv\"))\n",
    "    genes = list(genes_df.iloc[:, 0])\n",
    "    transcripts = pd.read_parquet(os.path.join(data_path, \"processed_data/transcripts.parquet\"))\n",
    "    if \"target\" not in transcripts.columns and \"gene\" in transcripts.columns:\n",
    "        transcripts = transcripts.rename(columns={\"gene\": \"target\"})\n",
    "    return genes, transcripts\n",
    "\n",
    "def build_mc(transcripts, nc_genes, **kwargs):\n",
    "    \"\"\"Build mcDETECT instance for profile().\"\"\"\n",
    "    return mcDETECT(\n",
    "        type=\"discrete\",\n",
    "        transcripts=transcripts,\n",
    "        gnl_genes=ref_genes[:20],\n",
    "        nc_genes=nc_genes or [],\n",
    "        eps=1.5, minspl=3, grid_len=1, cutoff_prob=0.95, alpha=10, low_bound=3, size_thr=4.0,\n",
    "        in_soma_thr=0.1, l=1, rho=0.2, s=1, nc_top=20, nc_thr=0.1,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load genes and transcripts once (for profile() when data are parquet)\n",
    "genes_wt, transcripts_wt = load_genes_and_transcripts(DATA_PATH_WT)\n",
    "genes_ad, transcripts_ad = load_genes_and_transcripts(DATA_PATH_AD)\n",
    "nc_wt = list(pd.read_csv(os.path.join(DATA_PATH_WT, \"processed_data/negative_controls.csv\"))[\"Gene\"])\n",
    "nc_ad = list(pd.read_csv(os.path.join(DATA_PATH_AD, \"processed_data/negative_controls.csv\"))[\"Gene\"])\n",
    "ref_genes_common = [g for g in ref_genes if g in genes_wt and g in genes_ad]\n",
    "print(f\"Marker genes present in both WT and AD: {len(ref_genes_common)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_sample(path, sample_label, genes, transcripts, mc, is_parquet):\n",
    "    \"\"\"Load a single WT or AD sample from one file. Returns adata with obs['sample'] = sample_label.\"\"\"\n",
    "    if is_parquet:\n",
    "        granules = pd.read_parquet(path)\n",
    "        adata = mc.profile(granules, genes=genes)\n",
    "    else:\n",
    "        adata = sc.read_h5ad(path)\n",
    "    adata.obs[\"sample\"] = sample_label\n",
    "    return adata\n",
    "\n",
    "def concatenate_wt_ad_for_setting(benchmark_name, filename, genes_wt, genes_ad, transcripts_wt, transcripts_ad, nc_wt, nc_ad, ref_genes_common):\n",
    "    \"\"\"\n",
    "    Load the **same filename** from WT and AD representative dirs for this benchmark, then concatenate.\n",
    "    - .parquet → build profile with mc.profile(granules, genes) for WT and AD separately.\n",
    "    - .h5ad → load directly.\n",
    "    Returns combined adata with obs['sample'] in ('WT', 'AD'), var restricted to ref_genes_common.\n",
    "    \"\"\"\n",
    "    wt_dir = os.path.join(BENCHMARK_ROOT, benchmark_name, WT_REPR_DIR)\n",
    "    ad_dir = os.path.join(BENCHMARK_ROOT, benchmark_name, AD_REPR_DIR)\n",
    "    path_wt = os.path.join(wt_dir, filename)\n",
    "    path_ad = os.path.join(ad_dir, filename)\n",
    "    if not os.path.isfile(path_wt):\n",
    "        raise FileNotFoundError(f\"WT file not found: {path_wt}\")\n",
    "    if not os.path.isfile(path_ad):\n",
    "        raise FileNotFoundError(f\"AD file not found: {path_ad}\")\n",
    "\n",
    "    is_parquet = filename.endswith(\".parquet\")\n",
    "    if is_parquet:\n",
    "        mc_wt = build_mc(transcripts_wt, nc_wt)\n",
    "        mc_ad = build_mc(transcripts_ad, nc_ad)\n",
    "        adata_wt = load_one_sample(path_wt, \"WT\", genes_wt, transcripts_wt, mc_wt, True)\n",
    "        adata_ad = load_one_sample(path_ad, \"AD\", genes_ad, transcripts_ad, mc_ad, True)\n",
    "    else:\n",
    "        adata_wt = load_one_sample(path_wt, \"WT\", None, None, None, False)\n",
    "        adata_ad = load_one_sample(path_ad, \"AD\", None, None, None, False)\n",
    "\n",
    "    common = [g for g in ref_genes_common if g in adata_wt.var_names and g in adata_ad.var_names]\n",
    "    adata_wt = adata_wt[:, common].copy()\n",
    "    adata_ad = adata_ad[:, common].copy()\n",
    "    adata = anndata.concat([adata_wt, adata_ad], join=\"outer\", label=\"sample\", keys=[\"WT\", \"AD\"])\n",
    "    adata.obs[\"sample\"] = adata.obs[\"sample\"].astype(str)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-setting pipeline: subtyping and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means and manual subtyping parameters (reproducibility: all driven by SEED)\n",
    "N_CLUSTERS = 15\n",
    "KMEANS_BATCH_SIZE = 5000\n",
    "KMEANS_N_INIT = 50\n",
    "\n",
    "# Brain areas for density (match 3_post_detection)\n",
    "AREA_LIST = [\"Isocortex\", \"OLF\", \"HPF-CA\", \"HPF-DG\", \"HPF-SR\", \"CTXsp\", \"TH\", \"MB\", \"FT\"]\n",
    "\n",
    "# Synaptic subtypes for density summary and correlation with ground truth (finer annotation column used if available)\n",
    "SYNAPTIC_SUBTYPES = [\"pre-syn\", \"post-syn\", \"pre & post\"]\n",
    "GROUND_TRUTH_DENSITIES = [1.71603565, 1.964351308, 2.052720791, 1.139278326, 99, 1.678527951, 1.082904337, 0.444031185, 0.0199885]  # 99 = placeholder for HPF-SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual subtyping: k-means (fixed seed) + heatmap, annotation left blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_category_features(granule_adata, marker_genes, agg=\"mean\"):\n",
    "    \"\"\"Build (n_obs x 4) matrix: one value per category (pre-syn, post-syn, dendrites, axons).\n",
    "    agg: 'mean' or 'sum' over genes in that category present in adata.var_names.\"\"\"\n",
    "    var_names = set(granule_adata.var_names)\n",
    "    X = granule_adata.X\n",
    "    if hasattr(X, \"toarray\"):\n",
    "        X = X.toarray()\n",
    "    else:\n",
    "        X = np.asarray(X)\n",
    "    cat_order = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\"]\n",
    "    cols = []\n",
    "    for cat in cat_order:\n",
    "        genes = [g for g in marker_genes.get(cat, []) if g in var_names]\n",
    "        if len(genes) == 0:\n",
    "            cols.append(np.zeros(granule_adata.n_obs, dtype=np.float32))\n",
    "            continue\n",
    "        idx = [list(granule_adata.var_names).index(g) for g in genes]\n",
    "        block = X[:, np.array(idx)]\n",
    "        if agg == \"mean\":\n",
    "            cols.append(block.mean(axis=1).astype(np.float32))\n",
    "        else:\n",
    "            cols.append(block.sum(axis=1).astype(np.float32))\n",
    "    return np.column_stack(cols)\n",
    "\n",
    "def run_manual_subtyping(granule_adata, n_clusters, seed, batch_size=5000, n_init=50, use_category_markers=False, marker_genes=None, category_agg=\"mean\"):\n",
    "    \"\"\"\n",
    "    K-means; all randomness controlled by seed.\n",
    "    - use_category_markers=False: K-means on full marker matrix → obs['granule_subtype_kmeans'].\n",
    "    - use_category_markers=True: K-means on 4 category-level features (pre, post, den, axon) → obs['granule_subtype_kmeans_category'].\n",
    "      Requires marker_genes dict with keys 'pre-syn', 'post-syn', 'dendrites', 'axons'.\n",
    "    \"\"\"\n",
    "    if use_category_markers and marker_genes is None:\n",
    "        raise ValueError(\"marker_genes required when use_category_markers=True\")\n",
    "    obs_key = \"granule_subtype_kmeans_category\" if use_category_markers else \"granule_subtype_kmeans\"\n",
    "    if use_category_markers:\n",
    "        data = _build_category_features(granule_adata, marker_genes, agg=category_agg)\n",
    "    else:\n",
    "        data = granule_adata.X.copy()\n",
    "        if hasattr(data, \"toarray\"):\n",
    "            data = data.toarray()\n",
    "    np.random.seed(seed)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, random_state=seed, n_init=n_init)\n",
    "    kmeans.fit(data)\n",
    "    granule_adata.obs[obs_key] = kmeans.labels_.astype(str)\n",
    "    desired_order = [str(i) for i in range(n_clusters)]\n",
    "    granule_adata.obs[obs_key] = pd.Categorical(granule_adata.obs[obs_key], categories=desired_order, ordered=True)\n",
    "    return granule_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adata_for_category_heatmap(granule_adata, marker_genes, category_agg=\"mean\"):\n",
    "    \"\"\"Build AnnData with 4 vars (pre-syn, post-syn, dendrites, axons) and same obs, for heatmap when using category-level clustering.\"\"\"\n",
    "    X_cat = _build_category_features(granule_adata, marker_genes, agg=category_agg)\n",
    "    cat_names = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\"]\n",
    "    adata_cat = anndata.AnnData(X=X_cat.astype(np.float32), obs=granule_adata.obs.copy())\n",
    "    adata_cat.var_names = cat_names\n",
    "    adata_cat.var[\"genes\"] = cat_names\n",
    "    return adata_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual annotation: map k-means cluster id -> subtype. Fill in based on your heatmap; leave blank for framework.\n",
    "def apply_manual_annotation(granule_adata, mapping, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"Map cluster labels to subtype from mapping dict; add obs['granule_subtype'] and 'granule_subtype_manual' (mixed vs pure).\n",
    "    cluster_column: e.g. 'granule_subtype_kmeans' or 'granule_subtype_kmeans_category'.\"\"\"\n",
    "    k2sub = {}\n",
    "    for subtype, clusters in mapping.items():\n",
    "        for c in clusters:\n",
    "            k2sub[c] = subtype\n",
    "    granule_adata.obs[\"granule_subtype\"] = granule_adata.obs[cluster_column].astype(str).map(k2sub)\n",
    "    granule_adata.obs[\"granule_subtype_manual\"] = granule_adata.obs[\"granule_subtype\"].apply(\n",
    "        lambda s: \"mixed\" if pd.notna(s) and \" & \" in str(s) else str(s)\n",
    "    )\n",
    "    return granule_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: annotate clusters with Scanpy score_genes\n",
    "\n",
    "After clustering (either gene-level or category-level), you can assign each cluster a subtype by the category whose mean score_genes is highest. No manual mapping needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic subtyping: GranuleSubtyper and hyperparameter tuning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps for tuning automatic subtyping (after you have manual annotation):\n",
    "# 1. Define manual distribution (proportions) from your manual annotation, e.g.:\n",
    "#    manual_dist = {'pre-syn': 0.16, 'post-syn': 0.31, 'dendrites': 0.17, 'axons': 0.0, 'mixed': 0.34, 'others': 0.02}\n",
    "# 2. Grid search: for (enrichment_threshold, min_zscore_threshold) run classify_granules with cluster_column='granule_subtype_kmeans'\n",
    "#    (or cluster_column=None for granule-level). Get proportion per subtype for each (enrich_thr, zscore_thr).\n",
    "# 3. Compute least_square_error = sum over subtypes of (auto_proportion - manual_proportion)^2.\n",
    "# 4. Pick (enrich_thr, zscore_thr) with smallest LSE; use that for final automatic labels.\n",
    "# See cells below for the actual grid and LSE computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_tuning_grid(granule_adata, marker_genes, manual_dist, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"\n",
    "    Grid over enrichment_threshold and min_zscore_threshold; compute LSE vs manual_dist.\n",
    "    manual_dist: dict e.g. {'pre-syn': 0.16, 'post-syn': 0.31, 'dendrites': 0.17, 'axons': 0.0, 'mixed': 0.34, 'others': 0.02}\n",
    "    Returns (results_df, best_enrich_thr, best_zscore_thr).\n",
    "    \"\"\"\n",
    "    enrich_thresholds = [0.2, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50]\n",
    "    zscore_thresholds = [-0.5, -0.25, 0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "    dist_cols = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\", \"mixed\", \"others\"]\n",
    "    manual_series = pd.Series(manual_dist).reindex(dist_cols).fillna(0)\n",
    "\n",
    "    results = []\n",
    "    for enrich_thr in enrich_thresholds:\n",
    "        for zscore_thr in zscore_thresholds:\n",
    "            subtypes, subtypes_simple = classify_granules(\n",
    "                granule_adata,\n",
    "                cluster_column=cluster_column,\n",
    "                enrichment_threshold=enrich_thr,\n",
    "                min_zscore_threshold=zscore_thr,\n",
    "                custom_markers=marker_genes,\n",
    "            )\n",
    "            counts = subtypes_simple.value_counts(normalize=True)\n",
    "            row = {\n",
    "                \"enrich_thr\": enrich_thr,\n",
    "                \"zscore_thr\": zscore_thr,\n",
    "                **{c: counts.get(c, 0) for c in dist_cols},\n",
    "            }\n",
    "            results.append(row)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df[\"least_square_error\"] = (\n",
    "        (results_df[dist_cols].sub(manual_series, axis=1)) ** 2\n",
    "    ).sum(axis=1)\n",
    "    best = results_df.sort_values(\"least_square_error\", ascending=True).iloc[0]\n",
    "    return results_df, best[\"enrich_thr\"], best[\"zscore_thr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_subtyping(granule_adata, marker_genes, enrichment_threshold=0.35, min_zscore_threshold=0.0, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"Assign obs['granule_subtype_automated'] and 'granule_subtype_automated_simple' (mixed vs pure).\"\"\"\n",
    "    subtypes, subtypes_simple = classify_granules(\n",
    "        granule_adata,\n",
    "        cluster_column=cluster_column,\n",
    "        enrichment_threshold=enrichment_threshold,\n",
    "        min_zscore_threshold=min_zscore_threshold,\n",
    "        custom_markers=marker_genes,\n",
    "    )\n",
    "    granule_adata.obs[\"granule_subtype_automated\"] = subtypes.values\n",
    "    granule_adata.obs[\"granule_subtype_automated_simple\"] = subtypes_simple.values\n",
    "    return granule_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export labels (parquet) and subtype density (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subtype_density_per_region(granule_obs, spots, area_col=\"brain_area\", subtype_col=\"granule_subtype_manual\",\n",
    "                                        sample_col=\"sample\", coord_keys=(\"global_x\", \"global_y\"), grid_len=50):\n",
    "    \"\"\"\n",
    "    Spot-level density per subtype: for each (sample, brain_area, subtype), density = sum(granule count in that area) / n_spots in that area.\n",
    "    granule_obs must have coords (global_x, global_y or sphere_x, sphere_y), sample_col, and subtype_col.\n",
    "    spots is AnnData with spots.obs containing area_col and coord_keys.\n",
    "    \"\"\"\n",
    "    if area_col not in spots.obs.columns or coord_keys[0] not in spots.obs.columns or coord_keys[1] not in spots.obs.columns:\n",
    "        return pd.DataFrame()\n",
    "    half = grid_len / 2\n",
    "    rows = []\n",
    "    for sample in granule_obs[sample_col].dropna().unique():\n",
    "        go = granule_obs[granule_obs[sample_col] == sample].copy()\n",
    "        xcol = \"global_x\" if \"global_x\" in go.columns else \"sphere_x\"\n",
    "        ycol = \"global_y\" if \"global_y\" in go.columns else \"sphere_y\"\n",
    "        if xcol not in go.columns or ycol not in go.columns:\n",
    "            continue\n",
    "        for area in spots.obs[area_col].dropna().unique():\n",
    "            sp = spots.obs.loc[spots.obs[area_col] == area]\n",
    "            n_spots = len(sp)\n",
    "            if n_spots == 0:\n",
    "                continue\n",
    "            for subtype in go[subtype_col].dropna().unique():\n",
    "                gs = go.loc[go[subtype_col] == subtype]\n",
    "                total = 0\n",
    "                for _, srow in sp.iterrows():\n",
    "                    x, y = srow[coord_keys[0]], srow[coord_keys[1]]\n",
    "                    in_spot = (gs[xcol].values >= x - half) & (gs[xcol].values < x + half) & (gs[ycol].values >= y - half) & (gs[ycol].values < y + half)\n",
    "                    total += in_spot.sum()\n",
    "                density = total / n_spots\n",
    "                rows.append({\"sample\": sample, \"brain_area\": area, \"subtype\": subtype, \"density\": density, \"n_spots\": n_spots})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Simpler variant: proportion per (sample, subtype) or per (sample, brain_area, subtype) when area_col present.\n",
    "def compute_subtype_density_simple(granule_obs, area_col=\"brain_area\", subtype_col=\"granule_subtype_manual\", sample_col=\"sample\"):\n",
    "    \"\"\"Density = count / total granules per sample. If area_col in obs, group by (sample, brain_area, subtype); else (sample, subtype) with brain_area='all'.\"\"\"\n",
    "    total_per_sample = granule_obs.groupby(sample_col).size()\n",
    "    if area_col in granule_obs.columns:\n",
    "        g = granule_obs.groupby([sample_col, area_col, subtype_col], dropna=False).size().reset_index(name=\"count\")\n",
    "        g[\"density\"] = g.apply(lambda r: r[\"count\"] / total_per_sample[r[sample_col]], axis=1)\n",
    "        g[\"n_spots\"] = np.nan\n",
    "    else:\n",
    "        g = granule_obs.groupby([sample_col, subtype_col], dropna=False).size().reset_index(name=\"count\")\n",
    "        g[\"density\"] = g.apply(lambda r: r[\"count\"] / total_per_sample[r[sample_col]], axis=1)\n",
    "        g[\"brain_area\"] = \"all\"\n",
    "        g[\"n_spots\"] = np.nan\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_setting_results(benchmark_name, setting_key, benchmark_root, comparison_dir, granule_adata, subtype_col=\"granule_subtype_manual\", density_df=None):\n",
    "    \"\"\"\n",
    "    Export to benchmark_xxx/WT_AD_comparison/ with setting-specific filenames:\n",
    "    - granule_subtype_labels_{setting_key}.parquet\n",
    "    - subtype_density_per_region_{setting_key}.csv\n",
    "    \"\"\"\n",
    "    out_dir = os.path.join(benchmark_root, benchmark_name, comparison_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    keep_cols = [c for c in [\"granule_id\", \"sample\", subtype_col, \"global_x\", \"global_y\", \"granule_subtype_kmeans\", \"granule_subtype_kmeans_category\", \"granule_subtype_score_genes\"] if c in granule_adata.obs.columns]\n",
    "    labels_df = granule_adata.obs[keep_cols].copy()\n",
    "    labels_df.to_parquet(os.path.join(out_dir, f\"granule_subtype_labels_{setting_key}.parquet\"), index=False)\n",
    "    if density_df is not None and len(density_df) > 0:\n",
    "        density_df.to_csv(os.path.join(out_dir, f\"subtype_density_per_region_{setting_key}.csv\"), index=False)\n",
    "    else:\n",
    "        density_simple = compute_subtype_density_simple(granule_adata.obs, subtype_col=subtype_col)\n",
    "        if len(density_simple) > 0:\n",
    "            density_simple.to_csv(os.path.join(out_dir, f\"subtype_density_per_region_{setting_key}.csv\"), index=False)\n",
    "    print(f\"Exported {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full pipeline for one setting (example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for the first available setting (or pick another index from BENCHMARK_SETTINGS)\n",
    "benchmark_name, filename = BENCHMARK_SETTINGS[0]\n",
    "setting_key = os.path.splitext(filename)[0]  # e.g. granules_rho_0.0 or granules_expression_default\n",
    "print(f\"Processing: {benchmark_name} / {filename}  (setting_key={setting_key})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate WT + AD adata (same filename in each representative dir)\n",
    "adata_combined = concatenate_wt_ad_for_setting(benchmark_name, filename, genes_wt, genes_ad, transcripts_wt, transcripts_ad, nc_wt, nc_ad, ref_genes_common)\n",
    "\n",
    "sc.pp.normalize_total(adata_combined, target_sum=1e4)\n",
    "sc.pp.log1p(adata_combined)\n",
    "\n",
    "print(adata_combined.shape)\n",
    "print(adata_combined.obs[\"sample\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual subtyping: k-means with fixed seed (default: 34 genes → granule_subtype_kmeans)\n",
    "run_manual_subtyping(adata_combined, n_clusters=N_CLUSTERS, seed=SEED, batch_size=KMEANS_BATCH_SIZE, n_init=KMEANS_N_INIT)\n",
    "del adata_combined.obs[\"granule_subtype_kmeans_category\"]\n",
    "\n",
    "# Option: use 4 category-level features → stores in granule_subtype_kmeans_category\n",
    "# run_manual_subtyping(adata_combined, N_CLUSTERS, SEED, KMEANS_BATCH_SIZE, KMEANS_N_INIT, use_category_markers=True, marker_genes=marker_genes, category_agg=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for manual annotation: use 4 category-level markers when clustering was category-level, else 34 genes.\n",
    "if \"granule_subtype_kmeans_category\" in adata_combined.obs.columns:\n",
    "    adata_plot = adata_for_category_heatmap(adata_combined, marker_genes)\n",
    "    groupby = \"granule_subtype_kmeans_category\"\n",
    "    var_names = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\"]\n",
    "else:\n",
    "    adata_plot = adata_combined\n",
    "    groupby = \"granule_subtype_kmeans\"\n",
    "    ref_genes_sorted = [\"Bsn\", \"Gap43\", \"Nrxn1\", \"Slc17a6\", \"Slc17a7\", \"Slc32a1\", \"Stx1a\", \"Syn1\", \"Syp\", \"Syt1\", \"Vamp2\", \"Cplx2\",\n",
    "                       \"Camk2a\", \"Dlg3\", \"Dlg4\", \"Gphn\", \"Gria1\", \"Gria2\", \"Homer1\", \"Homer2\", \"Nlgn1\", \"Nlgn2\", \"Nlgn3\", \"Shank1\", \"Shank3\",\n",
    "                       \"Cyfip2\", \"Ddn\", \"Map1a\", \"Map2\", \"Ank3\", \"Nav1\", \"Nfasc\", \"Mapt\", \"Tubb3\"]\n",
    "    var_names = [g for g in ref_genes_sorted if g in adata_combined.var_names]\n",
    "    adata_plot.obs[groupby] = pd.Categorical(adata_plot.obs[groupby], categories=[str(i) for i in range(N_CLUSTERS)], ordered=True)\n",
    "ax = sc.pl.heatmap(adata_plot, var_names=var_names, groupby=groupby, cmap=\"Reds\", standard_scale=\"var\", dendrogram=False, swap_axes=True, show=False, figsize=(10, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MANUAL_SUBTYPE_MAPPING = {\n",
    "    \"pre-syn\": [\"2\", \"5\", \"6\", \"8\", \"13\"],\n",
    "    \"post-syn\": [\"0\", \"1\", \"7\"],\n",
    "    \"dendrites\": [\"3\", \"9\"],\n",
    "    \"axons\": [],\n",
    "    \"pre & post\": [\"4\"],\n",
    "    \"pre & den\": [],\n",
    "    \"post & den\": [\"11\", \"12\"],\n",
    "    \"pre & post & den\": [\"10\", \"14\"],\n",
    "    \"others\": [],\n",
    "}\n",
    "\n",
    "# MANUAL_SUBTYPE_MAPPING = {\n",
    "#     \"pre-syn\": [],\n",
    "#     \"post-syn\": [],\n",
    "#     \"dendrites\": [],\n",
    "#     \"axons\": [],\n",
    "#     \"pre & post\": [],\n",
    "#     \"pre & den\": [],\n",
    "#     \"post & den\": [],\n",
    "#     \"pre & post & den\": [],\n",
    "#     \"others\": [],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply manual mapping (after you fill MANUAL_SUBTYPE_MAPPING from the heatmap)\n",
    "cluster_col = \"granule_subtype_kmeans_category\" if \"granule_subtype_kmeans_category\" in adata_combined.obs.columns else \"granule_subtype_kmeans\"\n",
    "apply_manual_annotation(adata_combined, MANUAL_SUBTYPE_MAPPING, cluster_column=cluster_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_combined.obs[\"granule_subtype_manual\"].value_counts() / len(adata_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build manual_dist from manual annotation proportions (for run_automatic_tuning_grid)\n",
    "manual_props = adata_combined.obs[\"granule_subtype_manual\"].value_counts(normalize=True)\n",
    "manual_dist = {\"pre-syn\": 0.0, \"post-syn\": 0.0, \"dendrites\": 0.0, \"axons\": 0.0, \"mixed\": 0.0, \"others\": 0.0}\n",
    "for k, v in manual_props.items():\n",
    "    if k in manual_dist:\n",
    "        manual_dist[k] = float(v)\n",
    "    else:\n",
    "        manual_dist[\"others\"] = manual_dist.get(\"others\", 0) + float(v)\n",
    "manual_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic subtyping: tuning step (run after you have manual proportions)\n",
    "# manual_dist = {'pre-syn': 0.16, 'post-syn': 0.31, 'dendrites': 0.17, 'axons': 0.0, 'mixed': 0.34, 'others': 0.02}\n",
    "results_df, best_enrich, best_zscore = run_automatic_tuning_grid(adata_combined, marker_genes, manual_dist)\n",
    "print(results_df.sort_values('least_square_error').head(10))\n",
    "\n",
    "# Then run with best hyperparameters:\n",
    "# run_automatic_subtyping(adata_combined, marker_genes, enrichment_threshold=0.2, min_zscore_threshold=0.0)\n",
    "# Or: run_automatic_subtyping(adata_combined, marker_genes, enrichment_threshold=best_enrich, min_zscore_threshold=best_zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_combined.obs[\"granule_subtype_automated_simple\"].value_counts() / len(adata_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density: if spots with brain_area are available, use compute_subtype_density_per_region; else use simple density\n",
    "spots_wt = sc.read_h5ad(os.path.join(DATA_PATH_WT, \"processed_data/spots.h5ad\"))\n",
    "spots_ad = sc.read_h5ad(os.path.join(DATA_PATH_AD, \"processed_data/spots.h5ad\"))\n",
    "if \"brain_area\" in spots_wt.obs.columns and \"brain_area\" in spots_ad.obs.columns:\n",
    "    density_df_wt = compute_subtype_density_per_region(adata_combined.obs[adata_combined.obs[\"sample\"] == \"WT\"], spots_wt, subtype_col=\"granule_subtype_manual\")\n",
    "    density_df_ad = compute_subtype_density_per_region(adata_combined.obs[adata_combined.obs[\"sample\"] == \"AD\"], spots_ad, subtype_col=\"granule_subtype_manual\")\n",
    "    density_df = pd.concat([density_df_wt, density_df_ad], ignore_index=True)\n",
    "    density_df[\"setting\"] = setting_key\n",
    "else:\n",
    "    density_df = compute_subtype_density_simple(adata_combined.obs, subtype_col=\"granule_subtype_manual\")\n",
    "    density_df[\"setting\"] = setting_key\n",
    "print(density_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WT synaptic granule density vs ground truth: weighted Pearson and Spearman (HPF-SR excluded)\n",
    "if \"brain_area\" not in spots_wt.obs.columns:\n",
    "    print(f\"Setting {setting_key}: skip correlation (no brain_area in spots)\")\n",
    "else:\n",
    "    subtype_col_synaptic = \"granule_subtype_manual\" if \"granule_subtype_manual\" in adata_combined.obs.columns else (\"granule_subtype_automated_simple\" if \"granule_subtype_automated_simple\" in adata_combined.obs.columns else \"granule_subtype\")\n",
    "    obs_wt = adata_combined.obs[adata_combined.obs[\"sample\"] == \"WT\"].copy()\n",
    "    obs_wt_synaptic = obs_wt[obs_wt[subtype_col_synaptic].isin(SYNAPTIC_SUBTYPES)].copy()\n",
    "    obs_wt_synaptic[\"_synaptic_agg\"] = \"synaptic\"\n",
    "    density_synaptic_df = compute_subtype_density_per_region(obs_wt_synaptic, spots_wt, subtype_col=\"_synaptic_agg\")\n",
    "    df_wt_synaptic = density_synaptic_df[(density_synaptic_df[\"sample\"] == \"WT\") & (density_synaptic_df[\"subtype\"] == \"synaptic\")]\n",
    "    wt_density_list = df_wt_synaptic.set_index(\"brain_area\").reindex(AREA_LIST)[\"density\"].values\n",
    "    wt_density_list = np.nan_to_num(wt_density_list, nan=0.0)\n",
    "    wt_list_no_hpf = np.delete(wt_density_list, 4)\n",
    "    gt_no_hpf = np.delete(np.array(GROUND_TRUTH_DENSITIES), 4)\n",
    "    weights = [np.sum(spots_wt.obs[\"brain_area\"] == i) for i in AREA_LIST]\n",
    "    weights_no_hpf = weights.copy()\n",
    "    weights_no_hpf.pop(4)\n",
    "    scaled_wt = scale(wt_list_no_hpf)\n",
    "    scaled_gt = scale(gt_no_hpf)\n",
    "    r_pearson = weighted_corr(scaled_wt, scaled_gt, weights_no_hpf)\n",
    "    r_spearman = weighted_spearmanr(scaled_wt, scaled_gt, weights_no_hpf)\n",
    "    print(f\"Setting {setting_key}: weighted Pearson = {r_pearson:.4f}, weighted Spearman = {r_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export labels and density to benchmark_xxx/WT_AD_comparison/ (files named with setting_key)\n",
    "export_setting_results(\n",
    "    benchmark_name, setting_key, BENCHMARK_ROOT, COMPARISON_DIR, adata_combined,\n",
    "    subtype_col=\"granule_subtype_manual\", density_df=density_df\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcDETECT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
