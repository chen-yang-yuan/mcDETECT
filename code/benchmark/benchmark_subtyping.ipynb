{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granule subtyping for paired WT and AD benchmark samples\n",
    "\n",
    "This notebook completes granule subtyping and annotation for the **main result** (optimal mcDETECT) and for **benchmark settings** (benchmark_rho, benchmark_filtering, benchmark_sphere, etc.). The main result uses pre-built data at `output/MERSCOPE_WT_AD_comparison/granule_adata_tsne.h5ad` (already concatenated and normalized); for other settings we load from `MERSCOPE_WT_1_representative_data` and `MERSCOPE_AD_1_representative_data`. For each setting we:\n",
    "1. Load data (main result: load h5ad; benchmark: concatenate WT+AD and normalize).\n",
    "2. Subtype granules (manual: k-means + heatmap → annotation; optional automatic tuning).\n",
    "3. Export labels and density (main result and benchmark: per-setting files). For main result only: save tSNE and heatmap as jpeg to `output/MERSCOPE_WT_AD_comparison/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from mcDETECT.utils import *\n",
    "from mcDETECT.model import mcDETECT\n",
    "from mcDETECT.downstream import classify_granules\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark root: output/benchmark/\n",
    "BENCHMARK_ROOT = \"../../output/benchmark/\"\n",
    "\n",
    "# Data paths for WT and AD (for transcripts, genes, spots when building profiles or computing density)\n",
    "DATA_PATH_WT = \"../../data/MERSCOPE_WT_1/\"\n",
    "DATA_PATH_AD = \"../../data/MERSCOPE_AD_1/\"\n",
    "\n",
    "# Folder names for representative data under each benchmark_xxx\n",
    "WT_REPR_DIR = \"MERSCOPE_WT_1_representative_data\"\n",
    "AD_REPR_DIR = \"MERSCOPE_AD_1_representative_data\"\n",
    "\n",
    "# Output subfolder under each benchmark_xxx for labels and density\n",
    "COMPARISON_DIR = \"WT_AD_comparison\"\n",
    "\n",
    "# Main result: pre-built concatenated + normalized adata with tSNE\n",
    "MAIN_RESULT_DIR = \"../../output/MERSCOPE_WT_AD_comparison\"\n",
    "MAIN_RESULT_PATH = os.path.join(MAIN_RESULT_DIR, \"granule_adata_tsne.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Granule markers\n",
    "marker_genes = {\"pre-syn\": [\"Bsn\", \"Gap43\", \"Nrxn1\", \"Slc17a6\", \"Slc17a7\", \"Slc32a1\", \"Snap25\", \"Stx1a\", \"Syn1\", \"Syp\", \"Syt1\", \"Vamp2\", \"Cplx2\"],\n",
    "                \"post-syn\": [\"Camk2a\", \"Dlg3\", \"Dlg4\", \"Gphn\", \"Gria1\", \"Gria2\", \"Homer1\", \"Homer2\", \"Nlgn1\", \"Nlgn2\", \"Nlgn3\", \"Shank1\", \"Shank3\"],\n",
    "                \"axons\": [\"Ank3\", \"Nav1\", \"Sptnb4\", \"Nfasc\", \"Mapt\", \"Tubb3\"],\n",
    "                \"dendrites\": [\"Actb\", \"Cyfip2\", \"Ddn\", \"Dlg4\", \"Map1a\", \"Map2\"]}\n",
    "ref_genes = [\"Bsn\", \"Gap43\", \"Nrxn1\", \"Slc17a6\", \"Slc17a7\", \"Slc32a1\", \"Stx1a\", \"Syn1\", \"Syp\", \"Syt1\", \"Vamp2\", \"Cplx2\", \"Camk2a\", \"Dlg3\", \"Dlg4\", \"Gphn\", \"Gria1\", \"Gria2\", \"Homer1\", \"Homer2\", \"Nlgn1\", \"Nlgn2\", \"Nlgn3\", \"Shank1\", \"Shank3\", \"Cyfip2\", \"Ddn\", \"Map1a\", \"Map2\", \"Ank3\", \"Nav1\", \"Nfasc\", \"Mapt\", \"Tubb3\"]\n",
    "gnl_genes = [\"Camk2a\", \"Cplx2\", \"Slc17a7\", \"Ddn\", \"Syp\", \"Map1a\", \"Shank1\", \"Syn1\", \"Gria1\", \"Gria2\", \"Cyfip2\", \"Vamp2\", \"Bsn\", \"Slc32a1\", \"Nfasc\", \"Syt1\", \"Tubb3\", \"Nav1\", \"Shank3\", \"Mapt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explicit list of benchmark settings\n",
    "\n",
    "Under each benchmark (benchmark_rho, benchmark_filtering, benchmark_sphere), WT and AD outputs are stored in\n",
    "`MERSCOPE_WT_1_representative_data/` and `MERSCOPE_AD_1_representative_data/` with **the same filename** for a given parameter setting.\n",
    "Format is inferred from extension: `.parquet` → granules, build profile via mc.profile(); `.h5ad` → expression profile, load directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main result first, then benchmark settings.\n",
    "# (benchmark_name, filename) — for benchmark: same filename in WT and AD folders. For main_result: filename used as setting_key.\n",
    "BENCHMARK_SETTINGS = [\n",
    "    \n",
    "    # main_result: pre-built concatenated + normalized; not from benchmark dirs\n",
    "    (\"main_result\", \"granule_adata_tsne.h5ad\"), \n",
    "    \n",
    "    # benchmark_filtering: inSomaThr and ncThr (parquet)\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr1.0_ncThr1.0.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr0.1_ncThr1.0.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr1.0_ncThr0.1.parquet\"),\n",
    "    (\"benchmark_filtering\", \"granules_inSomaThr0.1_ncThr0.1.parquet\"),\n",
    "    \n",
    "    # benchmark_sphere: radius setting (h5ad = expression profile)\n",
    "    (\"benchmark_sphere\", \"granules_expression_default.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_fixed.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_expand.h5ad\"),\n",
    "    (\"benchmark_sphere\", \"granules_expression_shrink.h5ad\"),\n",
    "    \n",
    "    # # benchmark_rho: representative rho values (parquet)\n",
    "    # (\"benchmark_rho\", \"granules_rho_0.0.parquet\"),\n",
    "    # (\"benchmark_rho\", \"granules_rho_0.2.parquet\"),\n",
    "    # (\"benchmark_rho\", \"granules_rho_0.4.parquet\"),\n",
    "    # (\"benchmark_rho\", \"granules_rho_0.6.parquet\"),\n",
    "    \n",
    "]\n",
    "print(f\"Total settings: {len(BENCHMARK_SETTINGS)}\")\n",
    "\n",
    "for bench, fname in BENCHMARK_SETTINGS:\n",
    "    fmt = \"parquet (build profile)\" if fname.endswith(\".parquet\") else \"h5ad (load)\"\n",
    "    print(f\"  {bench} / {fname}  [{fmt}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load one file per sample and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_genes_and_transcripts(data_path):\n",
    "    genes_df = pd.read_csv(os.path.join(data_path, \"processed_data/genes.csv\"))\n",
    "    genes = list(genes_df.iloc[:, 0])\n",
    "    transcripts = pd.read_parquet(os.path.join(data_path, \"processed_data/transcripts.parquet\"))\n",
    "    if \"target\" not in transcripts.columns and \"gene\" in transcripts.columns:\n",
    "        transcripts = transcripts.rename(columns={\"gene\": \"target\"})\n",
    "    return genes, transcripts\n",
    "\n",
    "def build_mc(transcripts, gnl_genes, nc_genes, **kwargs):\n",
    "    \"\"\"Build mcDETECT instance for profile().\"\"\"\n",
    "    return mcDETECT(type=\"discrete\", transcripts=transcripts, gnl_genes=gnl_genes, nc_genes=nc_genes or [],\n",
    "        eps=1.5, minspl=3, grid_len=1, cutoff_prob=0.95, alpha=10, low_bound=3, size_thr=4.0,\n",
    "        in_soma_thr=0.1, l=1, rho=0.2, s=1, nc_top=20, nc_thr=0.1, **kwargs)\n",
    "\n",
    "def load_one_sample(path, sample_label, genes, mc, is_parquet):\n",
    "    \"\"\"Load a single WT or AD sample from one file. Returns adata with obs['sample'] = sample_label.\"\"\"\n",
    "    if is_parquet:\n",
    "        granules = pd.read_parquet(path)\n",
    "        adata = mc.profile(granules, genes=genes)\n",
    "    else:\n",
    "        adata = sc.read_h5ad(path)\n",
    "    adata.obs[\"sample\"] = sample_label\n",
    "    return adata\n",
    "\n",
    "def concatenate_wt_ad_for_setting(benchmark_name, filename, genes_wt, genes_ad, transcripts_wt, transcripts_ad, nc_wt, nc_ad, ref_genes_common):\n",
    "    \"\"\"\n",
    "    Load the **same filename** from WT and AD representative dirs for this benchmark, then concatenate.\n",
    "    - .parquet → build profile with mc.profile(granules, genes) for WT and AD separately.\n",
    "    - .h5ad → load directly.\n",
    "    Returns combined adata with obs['sample'] in ('WT', 'AD'), var restricted to ref_genes_common.\n",
    "    \"\"\"\n",
    "    wt_dir = os.path.join(BENCHMARK_ROOT, benchmark_name, WT_REPR_DIR)\n",
    "    ad_dir = os.path.join(BENCHMARK_ROOT, benchmark_name, AD_REPR_DIR)\n",
    "    path_wt = os.path.join(wt_dir, filename)\n",
    "    path_ad = os.path.join(ad_dir, filename)\n",
    "    if not os.path.isfile(path_wt):\n",
    "        raise FileNotFoundError(f\"WT file not found: {path_wt}\")\n",
    "    if not os.path.isfile(path_ad):\n",
    "        raise FileNotFoundError(f\"AD file not found: {path_ad}\")\n",
    "\n",
    "    is_parquet = filename.endswith(\".parquet\")\n",
    "    if is_parquet:\n",
    "        mc_wt = build_mc(transcripts_wt, gnl_genes=gnl_genes, nc_genes=nc_wt)\n",
    "        mc_ad = build_mc(transcripts_ad, gnl_genes=gnl_genes, nc_genes=nc_ad)\n",
    "        adata_wt = load_one_sample(path_wt, \"WT\", genes_wt, mc_wt, True)\n",
    "        adata_ad = load_one_sample(path_ad, \"AD\", genes_ad, mc_ad, True)\n",
    "    else:\n",
    "        adata_wt = load_one_sample(path_wt, \"WT\", None, None, None, False)\n",
    "        adata_ad = load_one_sample(path_ad, \"AD\", None, None, None, False)\n",
    "\n",
    "    common = [g for g in ref_genes_common if g in adata_wt.var_names and g in adata_ad.var_names]\n",
    "    adata_wt = adata_wt[:, common].copy()\n",
    "    adata_ad = adata_ad[:, common].copy()\n",
    "    adata = anndata.concat([adata_wt, adata_ad], join=\"outer\", label=\"sample\", keys=[\"WT\", \"AD\"])\n",
    "    adata.obs[\"sample\"] = adata.obs[\"sample\"].astype(str)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load genes and transcripts once (for profile() when data are parquet)\n",
    "genes_wt, transcripts_wt = load_genes_and_transcripts(DATA_PATH_WT)\n",
    "genes_ad, transcripts_ad = load_genes_and_transcripts(DATA_PATH_AD)\n",
    "nc_wt = list(pd.read_csv(os.path.join(DATA_PATH_WT, \"processed_data/negative_controls.csv\"))[\"Gene\"])\n",
    "nc_ad = list(pd.read_csv(os.path.join(DATA_PATH_AD, \"processed_data/negative_controls.csv\"))[\"Gene\"])\n",
    "ref_genes_common = [g for g in ref_genes if g in genes_wt and g in genes_ad]\n",
    "print(f\"Marker genes present in both WT and AD: {len(ref_genes_common)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Per-setting pipeline: subtyping and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means and manual subtyping parameters (reproducibility: all driven by SEED)\n",
    "N_CLUSTERS = 15\n",
    "KMEANS_BATCH_SIZE = 5000\n",
    "KMEANS_N_INIT = 20\n",
    "\n",
    "# Main result only: additional k values for cluster-count sensitivity (only subtype labels parquet saved; no tSNE/heatmap/density)\n",
    "MAIN_RESULT_EXTRA_K = [20, 25, 30]\n",
    "\n",
    "# Brain areas for density\n",
    "AREA_LIST = [\"Isocortex\", \"OLF\", \"HPF-CA\", \"HPF-DG\", \"HPF-SR\", \"CTXsp\", \"TH\", \"MB\", \"FT\"]\n",
    "\n",
    "# Convention: granule_subtype_manual = finer labels (e.g. 'pre & post'); use only for defining synaptic granules. Density and automatic-annotation guidance use granule_subtype_manual_simple ('mixed' for mixed types).\n",
    "# Synaptic subtypes (from granule_subtype_manual) for correlation with ground truth\n",
    "SYNAPTIC_SUBTYPES = [\"pre-syn\", \"post-syn\", \"pre & post\"]\n",
    "GROUND_TRUTH_DENSITIES = [1.71603565, 1.964351308, 2.052720791, 1.139278326, 99, 1.678527951, 1.082904337, 0.444031185, 0.0199885]  # 99 = placeholder for HPF-SR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Manual subtyping: k-means (fixed seed) + heatmap, annotation left blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual_subtyping(granule_adata, n_clusters, seed, batch_size=5000, n_init=20, obs_key=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"K-means on full marker matrix → obs[obs_key]; all randomness controlled by seed.\"\"\"\n",
    "    data = granule_adata.X.copy()\n",
    "    if hasattr(data, \"toarray\"):\n",
    "        data = data.toarray()\n",
    "    np.random.seed(seed)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=n_clusters, batch_size=batch_size, random_state=seed, n_init=n_init)\n",
    "    kmeans.fit(data)\n",
    "    granule_adata.obs[obs_key] = kmeans.labels_.astype(str)\n",
    "    desired_order = [str(i) for i in range(n_clusters)]\n",
    "    granule_adata.obs[obs_key] = pd.Categorical(granule_adata.obs[obs_key], categories=desired_order, ordered=True)\n",
    "    return granule_adata\n",
    "\n",
    "def apply_manual_annotation(granule_adata, mapping, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"Map cluster labels to subtype from mapping dict; add obs['granule_subtype_manual'] and obs['granule_subtype_manual_simple'].\"\"\"\n",
    "    k2sub = {}\n",
    "    for subtype, clusters in mapping.items():\n",
    "        for c in clusters:\n",
    "            k2sub[c] = subtype\n",
    "    granule_adata.obs[\"granule_subtype_manual\"] = granule_adata.obs[cluster_column].astype(str).map(k2sub)\n",
    "    granule_adata.obs[\"granule_subtype_manual_simple\"] = granule_adata.obs[\"granule_subtype_manual\"].apply(\n",
    "        lambda s: \"mixed\" if pd.notna(s) and \" & \" in str(s) else str(s)\n",
    "    )\n",
    "    return granule_adata\n",
    "\n",
    "def compute_manual_dist(granule_adata, subtype_column=\"granule_subtype_manual_simple\"):\n",
    "    \"\"\"Build manual_dist from granule_subtype_manual_simple (for run_automatic_tuning_grid)\"\"\"\n",
    "    manual_props = granule_adata.obs[subtype_column].value_counts(normalize=True)\n",
    "    manual_dist = {\"pre-syn\": 0.0, \"post-syn\": 0.0, \"dendrites\": 0.0, \"axons\": 0.0, \"mixed\": 0.0, \"others\": 0.0}\n",
    "    for k, v in manual_props.items():\n",
    "        if k in manual_dist:\n",
    "            manual_dist[k] = float(v)\n",
    "        else:\n",
    "            manual_dist[\"others\"] = manual_dist.get(\"others\", 0) + float(v)\n",
    "    return manual_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Automatic subtyping: GranuleSubtyper and hyperparameter tuning steps\n",
    "\n",
    "Steps for tuning automatic subtyping (after you have manual annotation):\n",
    "1. Define manual distribution (proportions) from your manual annotation, e.g.:\n",
    "   manual_dist = {'pre-syn': 0.16, 'post-syn': 0.31, 'dendrites': 0.17, 'axons': 0.0, 'mixed': 0.34, 'others': 0.02}\n",
    "2. Grid search: for (enrichment_threshold, min_zscore_threshold) run classify_granules with cluster_column='granule_subtype_kmeans'\n",
    "   (or cluster_column=None for granule-level). Get proportion per subtype for each (enrich_thr, zscore_thr).\n",
    "3. Compute least_square_error = sum over subtypes of (auto_proportion - manual_proportion)^2.\n",
    "4. Pick (enrich_thr, zscore_thr) with smallest LSE; use that for final automatic labels.\n",
    "\n",
    "See cells below for the actual grid and LSE computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_automatic_tuning_grid(granule_adata, marker_genes, manual_dist, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"\n",
    "    Grid over enrichment_threshold and min_zscore_threshold; compute LSE vs manual_dist.\n",
    "    manual_dist: dict e.g. {'pre-syn': 0.16, 'post-syn': 0.31, 'dendrites': 0.17, 'axons': 0.0, 'mixed': 0.34, 'others': 0.02}\n",
    "    Returns (results_df, best_enrich_thr, best_zscore_thr).\n",
    "    \"\"\"\n",
    "    enrich_thresholds = [0.2, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.6]\n",
    "    zscore_thresholds = [-1, -0.5, 0.0, 0.5, 1.0, 1.5, 2]\n",
    "    dist_cols = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\", \"mixed\", \"others\"]\n",
    "    manual_series = pd.Series(manual_dist).reindex(dist_cols).fillna(0)\n",
    "\n",
    "    results = []\n",
    "    for enrich_thr in enrich_thresholds:\n",
    "        for zscore_thr in zscore_thresholds:\n",
    "            subtypes, subtypes_simple = classify_granules(\n",
    "                granule_adata,\n",
    "                cluster_column=cluster_column,\n",
    "                enrichment_threshold=enrich_thr,\n",
    "                min_zscore_threshold=zscore_thr,\n",
    "                custom_markers=marker_genes,\n",
    "            )\n",
    "            counts = subtypes_simple.value_counts(normalize=True)\n",
    "            row = {\n",
    "                \"enrich_thr\": enrich_thr,\n",
    "                \"zscore_thr\": zscore_thr,\n",
    "                **{c: counts.get(c, 0) for c in dist_cols},\n",
    "            }\n",
    "            results.append(row)\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df[\"least_square_error\"] = (\n",
    "        (results_df[dist_cols].sub(manual_series, axis=1)) ** 2\n",
    "    ).sum(axis=1)\n",
    "    best = results_df.sort_values(\"least_square_error\", ascending=True).iloc[0]\n",
    "    return results_df, best[\"enrich_thr\"], best[\"zscore_thr\"]\n",
    "\n",
    "def run_automatic_subtyping(granule_adata, marker_genes, enrichment_threshold=0.35, min_zscore_threshold=0.0, cluster_column=\"granule_subtype_kmeans\"):\n",
    "    \"\"\"Assign obs['granule_subtype_automated'] and 'granule_subtype_automated_simple' (mixed vs pure).\"\"\"\n",
    "    subtypes, subtypes_simple = classify_granules(\n",
    "        granule_adata,\n",
    "        cluster_column=cluster_column,\n",
    "        enrichment_threshold=enrichment_threshold,\n",
    "        min_zscore_threshold=min_zscore_threshold,\n",
    "        custom_markers=marker_genes,\n",
    "    )\n",
    "    granule_adata.obs[\"granule_subtype_automated\"] = subtypes.values\n",
    "    granule_adata.obs[\"granule_subtype_automated_simple\"] = subtypes_simple.values\n",
    "    return granule_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Export labels (parquet) and subtype density (CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subtype_density_per_region(granule_obs, spots, area_col=\"brain_area\", subtype_col=\"granule_subtype_manual_simple\",\n",
    "                                        sample_col=\"sample\", coord_keys=(\"global_x\", \"global_y\"), grid_len=50):\n",
    "    \"\"\"\n",
    "    Spot-level density per subtype: for each (sample, brain_area, subtype), density = sum(granule count in that area) / n_spots in that area.\n",
    "    granule_obs must have coords (global_x, global_y or sphere_x, sphere_y), sample_col, and subtype_col.\n",
    "    spots is AnnData with spots.obs containing area_col and coord_keys. Call with one sample's granule_obs and that sample's spots\n",
    "    (e.g. WT granules + WT spots, AD granules + AD spots) so coordinates are not mixed across samples.\n",
    "    \"\"\"\n",
    "    if area_col not in spots.obs.columns or coord_keys[0] not in spots.obs.columns or coord_keys[1] not in spots.obs.columns:\n",
    "        return pd.DataFrame()\n",
    "    half = grid_len / 2\n",
    "    rows = []\n",
    "    for sample in granule_obs[sample_col].dropna().unique():\n",
    "        go = granule_obs[granule_obs[sample_col] == sample].copy()\n",
    "        xcol = \"global_x\" if \"global_x\" in go.columns else \"sphere_x\"\n",
    "        ycol = \"global_y\" if \"global_y\" in go.columns else \"sphere_y\"\n",
    "        if xcol not in go.columns or ycol not in go.columns:\n",
    "            continue\n",
    "        for area in spots.obs[area_col].dropna().unique():\n",
    "            sp = spots.obs.loc[spots.obs[area_col] == area]\n",
    "            n_spots = len(sp)\n",
    "            if n_spots == 0:\n",
    "                continue\n",
    "            for subtype in go[subtype_col].dropna().unique():\n",
    "                gs = go.loc[go[subtype_col] == subtype]\n",
    "                total = 0\n",
    "                for _, srow in sp.iterrows():\n",
    "                    x, y = srow[coord_keys[0]], srow[coord_keys[1]]\n",
    "                    in_spot = (gs[xcol].values >= x - half) & (gs[xcol].values < x + half) & (gs[ycol].values >= y - half) & (gs[ycol].values < y + half)\n",
    "                    total += in_spot.sum()\n",
    "                density = total / n_spots\n",
    "                rows.append({\"sample\": sample, \"brain_area\": area, \"subtype\": subtype, \"density\": density, \"n_spots\": n_spots})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def export_setting_results(benchmark_name, setting_key, benchmark_root, comparison_dir, granule_adata, subtype_col=\"granule_subtype_manual_simple\", density_df=None, out_dir=None):\n",
    "    \"\"\"\n",
    "    Export to benchmark_xxx/WT_AD_comparison/ (or out_dir if provided) with setting-specific filenames:\n",
    "    - granule_subtype_labels_{setting_key}.parquet\n",
    "    - subtype_density_per_region_{setting_key}.csv\n",
    "    \"\"\"\n",
    "    out_dir = out_dir if out_dir is not None else os.path.join(benchmark_root, benchmark_name, comparison_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    keep_cols = [c for c in [\"granule_id\", \"sample\", subtype_col, \"global_x\", \"global_y\", \"granule_subtype_kmeans\", \"granule_subtype_manual\"] if c in granule_adata.obs.columns]\n",
    "    labels_df = granule_adata.obs[keep_cols].copy()\n",
    "    labels_df.to_parquet(os.path.join(out_dir, f\"granule_subtype_labels_{setting_key}.parquet\"), index=False)\n",
    "    if density_df is not None and len(density_df) > 0:\n",
    "        density_df.to_csv(os.path.join(out_dir, f\"subtype_density_per_region_{setting_key}.csv\"), index=False)\n",
    "    print(f\"Exported {out_dir}\")\n",
    "\n",
    "def export_labels_only(granule_adata, out_dir, setting_key, label_col, extra_cols=None):\n",
    "    \"\"\"Export only subtype labels parquet (e.g. for main result extra k); label_col = obs column with cluster ids.\"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    base = [\"granule_id\", \"sample\", label_col, \"global_x\", \"global_y\"]\n",
    "    keep = [c for c in (base + (extra_cols or [])) if c in granule_adata.obs.columns]\n",
    "    granule_adata.obs[keep].copy().to_parquet(os.path.join(out_dir, f\"granule_subtype_labels_{setting_key}.parquet\"), index=False)\n",
    "    print(f\"Exported labels {setting_key} -> {out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run full pipeline for one setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for the first available setting (or pick another index from BENCHMARK_SETTINGS)\n",
    "benchmark_name, filename = BENCHMARK_SETTINGS[0]\n",
    "setting_key = os.path.splitext(filename)[0]  # e.g. granules_rho_0.0 or granule_adata_tsne\n",
    "is_main_result = (benchmark_name == \"main_result\")\n",
    "print(f\"Processing: {benchmark_name} / {filename}  (setting_key={setting_key}, is_main_result={is_main_result})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: main result = pre-built h5ad (already normalized); else concatenate WT+AD and normalize\n",
    "if is_main_result:\n",
    "    adata_combined = sc.read_h5ad(MAIN_RESULT_PATH)\n",
    "    adata_combined.obs.rename(columns={\"batch\": \"sample\"}, inplace=True)\n",
    "    adata_combined.obs[\"sample_simple\"] = adata_combined.obs[\"sample\"].replace({\"MERSCOPE_WT_1\": \"WT\", \"MERSCOPE_AD_1\": \"AD\"})\n",
    "    print(adata_combined.shape)\n",
    "    print(adata_combined.obs[\"sample\"].value_counts())\n",
    "else:\n",
    "    adata_combined = concatenate_wt_ad_for_setting(benchmark_name, filename, genes_wt, genes_ad, transcripts_wt, transcripts_ad, nc_wt, nc_ad, ref_genes_common)\n",
    "    adata_combined.layers[\"counts\"] = csr_matrix(adata_combined.X.copy())\n",
    "    sc.pp.normalize_total(adata_combined, target_sum=1e4)\n",
    "    sc.pp.log1p(adata_combined)\n",
    "    print(adata_combined.shape)\n",
    "    print(adata_combined.obs[\"sample\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual subtyping: k-means with fixed seed (default: 34 genes → granule_subtype_kmeans)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "run_manual_subtyping(adata_combined, n_clusters=N_CLUSTERS, seed=SEED, batch_size=KMEANS_BATCH_SIZE, n_init=KMEANS_N_INIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap for manual annotation (always save to corresponding directory)\n",
    "groupby = \"granule_subtype_kmeans\"\n",
    "var_names = [g for g in ref_genes if g in adata_combined.var_names]\n",
    "adata_combined.obs[groupby] = pd.Categorical(adata_combined.obs[groupby], categories=[str(i) for i in range(N_CLUSTERS)], ordered=True)\n",
    "ax = sc.pl.heatmap(adata_combined, var_names=var_names, groupby=groupby, cmap=\"Reds\", standard_scale=\"var\", dendrogram=False, swap_axes=True, show=False, figsize=(10, 6))\n",
    "heatmap_out_dir = MAIN_RESULT_DIR if is_main_result else os.path.join(BENCHMARK_ROOT, benchmark_name, COMPARISON_DIR)\n",
    "os.makedirs(heatmap_out_dir, exist_ok=True)\n",
    "heatmap_fname = \"heatmap_subtype.jpeg\" if is_main_result else f\"heatmap_subtype_{setting_key}.jpeg\"\n",
    "plt.gcf().savefig(os.path.join(heatmap_out_dir, heatmap_fname), dpi=500, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [main result] seed = 42\n",
    "MANUAL_SUBTYPE_MAPPING = {\n",
    "    \"pre-syn\": [\"0\", \"7\", \"14\"],\n",
    "    \"post-syn\": [\"1\", \"3\", \"6\", \"10\"],\n",
    "    \"dendrites\": [\"2\", \"11\"],\n",
    "    \"axons\": [],\n",
    "    \"pre & post\": [\"9\"],\n",
    "    \"pre & den\": [],\n",
    "    \"post & den\": [\"4\", \"8\"],\n",
    "    \"pre & post & den\": [\"5\", \"12\", \"13\"],\n",
    "    \"others\": [],\n",
    "}\n",
    "\n",
    "# MANUAL_SUBTYPE_MAPPING = {\n",
    "#     \"pre-syn\": [],\n",
    "#     \"post-syn\": [],\n",
    "#     \"dendrites\": [],\n",
    "#     \"axons\": [],\n",
    "#     \"pre & post\": [],\n",
    "#     \"pre & den\": [],\n",
    "#     \"post & den\": [],\n",
    "#     \"pre & post & den\": [],\n",
    "#     \"others\": [],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply manual mapping (after you fill MANUAL_SUBTYPE_MAPPING from the heatmap)\n",
    "cluster_col = \"granule_subtype_kmeans\"\n",
    "apply_manual_annotation(adata_combined, MANUAL_SUBTYPE_MAPPING, cluster_column=cluster_col)\n",
    "adata_combined.obs[\"granule_subtype_manual_simple\"] = pd.Categorical(adata_combined.obs[\"granule_subtype_manual_simple\"], categories=[\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\", \"mixed\", \"others\"], ordered=True)\n",
    "adata_combined.obs[\"granule_subtype_manual_simple\"] = adata_combined.obs[\"granule_subtype_manual_simple\"].cat.remove_unused_categories()\n",
    "\n",
    "manual_dist = compute_manual_dist(adata_combined, subtype_column=\"granule_subtype_manual_simple\")\n",
    "print(manual_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main result only: ordered heatmap (x-axis by subtype: pre-syn, post-syn, dendrites, mixed, others; cluster colors match cluster id)\n",
    "if is_main_result:\n",
    "    orig_colors = list(adata_combined.uns.get(groupby + \"_colors\", []))\n",
    "    cluster_to_simple = {}\n",
    "    for subtype, clusters in MANUAL_SUBTYPE_MAPPING.items():\n",
    "        simple = \"mixed\" if (pd.notna(subtype) and \" & \" in str(subtype)) else str(subtype)\n",
    "        for c in clusters:\n",
    "            cluster_to_simple[str(c)] = simple\n",
    "    subtype_order = [\"pre-syn\", \"post-syn\", \"dendrites\", \"axons\", \"mixed\", \"others\"]\n",
    "    ordered_cluster_ids = []\n",
    "    for simple in subtype_order:\n",
    "        clusters_here = sorted([c for c, s in cluster_to_simple.items() if s == simple], key=lambda x: int(x))\n",
    "        ordered_cluster_ids.extend(clusters_here)\n",
    "    if len(ordered_cluster_ids) == 0:\n",
    "        ordered_cluster_ids = [str(i) for i in range(N_CLUSTERS)]\n",
    "    if len(orig_colors) >= N_CLUSTERS:\n",
    "        adata_combined.uns[groupby + \"_colors\"] = [orig_colors[int(c)] for c in ordered_cluster_ids]\n",
    "    adata_combined.obs[groupby] = pd.Categorical(adata_combined.obs[groupby].astype(str), categories=ordered_cluster_ids, ordered=True)\n",
    "    ax = sc.pl.heatmap(adata_combined, var_names=var_names, groupby=groupby, cmap=\"Reds\", standard_scale=\"var\", dendrogram=False, swap_axes=True, show=False, figsize=(10, 6))\n",
    "    plt.gcf().savefig(os.path.join(MAIN_RESULT_DIR, \"heatmap_subtype_ordered.jpeg\"), dpi=500, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    adata_combined.obs[groupby] = pd.Categorical(adata_combined.obs[groupby], categories=[str(i) for i in range(N_CLUSTERS)], ordered=True)\n",
    "    if len(orig_colors) >= N_CLUSTERS:\n",
    "        adata_combined.uns[groupby + \"_colors\"] = orig_colors[:N_CLUSTERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main result only: plot tSNE (already in data) colored by sample and granule subtype\n",
    "if is_main_result:\n",
    "    \n",
    "    # Plot tSNE colored by sample\n",
    "    sc.set_figure_params(figsize = (8, 8))\n",
    "    ax = sc.pl.tsne(adata_combined, color = \"sample_simple\", palette={\"WT\": \"#a0ccec\", \"AD\": \"#f48488\"}, size = 1, show = False)\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_title(\"\")\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    plt.gcf().savefig(os.path.join(MAIN_RESULT_DIR, \"granules_by_batch_tsne.jpeg\"), dpi=500, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot tSNE colored by granule subtype\n",
    "    for col in [\"granule_subtype_kmeans\", \"granule_subtype_manual\", \"granule_subtype_manual_simple\"]:\n",
    "        if adata_combined.obs[col].nunique() <= 10:\n",
    "            adata_combined = assign_palette_to_adata(adata_combined, obs_key = col, cmap_name = \"Set2\")\n",
    "        sc.set_figure_params(figsize = (8, 8))\n",
    "        ax = sc.pl.embedding(adata_combined, basis=\"tsne\", color=col, size=1, show=False)\n",
    "        ax.grid(False)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_title(\"\")\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "        plt.gcf().savefig(os.path.join(MAIN_RESULT_DIR, f\"{col}_tsne.jpeg\"), dpi=500, bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic subtyping: tuning step (run after you have manual proportions)\n",
    "results_df, best_enrich, best_zscore = run_automatic_tuning_grid(adata_combined, marker_genes, manual_dist, cluster_column=None)\n",
    "print(results_df.sort_values('least_square_error').head(10))\n",
    "\n",
    "# # Then run with best hyperparameters:\n",
    "# run_automatic_subtyping(adata_combined, marker_genes, enrichment_threshold=0.3, min_zscore_threshold=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density: use granule_subtype_manual_simple (mixed types → 'mixed'). Overlay granules to their sample's spots only.\n",
    "spots_wt = sc.read_h5ad(os.path.join(DATA_PATH_WT, \"processed_data/spots.h5ad\"))\n",
    "spots_ad = sc.read_h5ad(os.path.join(DATA_PATH_AD, \"processed_data/spots.h5ad\"))\n",
    "if \"brain_area\" in spots_wt.obs.columns and \"brain_area\" in spots_ad.obs.columns:\n",
    "    density_df_wt = compute_subtype_density_per_region(adata_combined.obs[adata_combined.obs[\"sample\"] == \"MERSCOPE_WT_1\"], spots_wt, subtype_col=\"granule_subtype_manual_simple\")\n",
    "    density_df_ad = compute_subtype_density_per_region(adata_combined.obs[adata_combined.obs[\"sample\"] == \"MERSCOPE_AD_1\"], spots_ad, subtype_col=\"granule_subtype_manual_simple\")\n",
    "    density_df = pd.concat([density_df_wt, density_df_ad], ignore_index=True)\n",
    "    density_df[\"setting\"] = setting_key\n",
    "print(density_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WT synaptic granule density vs ground truth (HPF-SR excluded). Synaptic granules defined by granule_subtype_manual only (SYNAPTIC_SUBTYPES).\n",
    "if \"brain_area\" not in spots_wt.obs.columns:\n",
    "    print(f\"Setting {setting_key}: skip correlation (no brain_area in spots)\")\n",
    "else:\n",
    "    subtype_col_synaptic = \"granule_subtype_manual\"  # use finer annotation only for defining synaptic\n",
    "    obs_wt = adata_combined.obs[adata_combined.obs[\"sample\"] == \"MERSCOPE_WT_1\"].copy()\n",
    "    obs_wt_synaptic = obs_wt[obs_wt[subtype_col_synaptic].isin(SYNAPTIC_SUBTYPES)].copy()\n",
    "    obs_wt_synaptic[\"_synaptic_agg\"] = \"synaptic\"\n",
    "    density_synaptic_df = compute_subtype_density_per_region(obs_wt_synaptic, spots_wt, subtype_col=\"_synaptic_agg\")\n",
    "    df_wt_synaptic = density_synaptic_df[(density_synaptic_df[\"sample\"] == \"MERSCOPE_WT_1\") & (density_synaptic_df[\"subtype\"] == \"synaptic\")]\n",
    "    wt_density_list = df_wt_synaptic.set_index(\"brain_area\").reindex(AREA_LIST)[\"density\"].values\n",
    "    wt_density_list = np.nan_to_num(wt_density_list, nan=0.0)\n",
    "    wt_list_no_hpfsr_ft = np.delete(wt_density_list, [4, 8])\n",
    "    gt_no_hpfsr_ft = np.delete(np.array(GROUND_TRUTH_DENSITIES), [4, 8])\n",
    "    weights = [np.sum(spots_wt.obs[\"brain_area\"] == i) for i in AREA_LIST]\n",
    "    weights_no_hpfsr_ft = weights.copy()\n",
    "    weights_no_hpfsr_ft.pop(8)\n",
    "    weights_no_hpfsr_ft.pop(4)\n",
    "    scaled_wt = scale(wt_list_no_hpfsr_ft)\n",
    "    scaled_gt = scale(gt_no_hpfsr_ft)\n",
    "    # r_pearson = weighted_corr(scaled_wt, scaled_gt, weights_no_hpfsr_ft)\n",
    "    # r_spearman = weighted_spearmanr(scaled_wt, scaled_gt, weights_no_hpfsr_ft)\n",
    "    r_pearson = weighted_corr(wt_list_no_hpfsr_ft, gt_no_hpfsr_ft, weights_no_hpfsr_ft)\n",
    "    r_spearman = weighted_spearmanr(wt_list_no_hpfsr_ft, gt_no_hpfsr_ft, weights_no_hpfsr_ft)\n",
    "    print(f\"Setting {setting_key}: weighted Pearson = {r_pearson:.4f}, weighted Spearman = {r_spearman:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export labels and density (main result → MAIN_RESULT_DIR, else benchmark_xxx/WT_AD_comparison/)\n",
    "if is_main_result:\n",
    "    export_setting_results(benchmark_name, setting_key, BENCHMARK_ROOT, COMPARISON_DIR, adata_combined, subtype_col=\"granule_subtype_manual_simple\", density_df=density_df, out_dir=MAIN_RESULT_DIR)\n",
    "else:\n",
    "    export_setting_results(benchmark_name, setting_key, BENCHMARK_ROOT, COMPARISON_DIR, adata_combined, subtype_col=\"granule_subtype_manual_simple\", density_df=density_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main result only: run k-means for extra k (20, 25, 30) and save subtype labels parquet only (no tSNE, heatmap, or density)\n",
    "if is_main_result:\n",
    "    for k in MAIN_RESULT_EXTRA_K:\n",
    "        run_manual_subtyping(adata_combined, n_clusters=k, seed=SEED, batch_size=KMEANS_BATCH_SIZE, n_init=KMEANS_N_INIT, obs_key=f\"granule_subtype_kmeans_k{k}\")\n",
    "        export_labels_only(adata_combined, MAIN_RESULT_DIR, f\"granule_adata_tsne_k{k}\", label_col=f\"granule_subtype_kmeans_k{k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcDETECT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
