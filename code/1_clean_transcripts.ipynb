{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import tifffile\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive thresholding with size filter and dilation\n",
    "def adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=10):\n",
    "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
    "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_contours = [c for c in contours if cv2.contourArea(c) >= min_area]\n",
    "    filtered_img = np.zeros_like(th)\n",
    "    cv2.drawContours(filtered_img, filtered_contours, -1, 255, -1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
    "    th_dilated = cv2.dilate(filtered_img, kernel)\n",
    "    return th_dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "settings = {\"MERSCOPE_WT_1\": {\"pixel_size\": 0.10799861, \"x_shift\": int(-266.1734), \"y_shift\": int(180.2510), \"cutoff\": 6250, \"theta\": 10 * np.pi / 180, \"coordinate_for_rotation\": [\"global_y\", \"global_x\"], \"coordinate_for_cutoff\": \"global_y\", \"cutoff_direction\": \"smaller\"},\n",
    "            \"MERSCOPE_AD_1\": {\"pixel_size\": 0.10799905, \"x_shift\": int(-126.9911), \"y_shift\": int(-20.3805), \"cutoff\": -4200, \"theta\": 170 * np.pi / 180, \"coordinate_for_rotation\": [\"global_x\", \"global_y\"], \"coordinate_for_cutoff\": \"global_x\", \"cutoff_direction\": \"larger\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Main operations on transcripts ==================== #\n",
    "\n",
    "in_soma_label = \"overlaps_nucleus_5_dilation\"\n",
    "\n",
    "for dataset in settings.keys():\n",
    "    \n",
    "    print(\"=\" * 25)\n",
    "    print(f\"Processing {dataset}...\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # File paths\n",
    "    data_path = f\"../data/{dataset}/\"\n",
    "    output_path = f\"../output/{dataset}/\"\n",
    "\n",
    "    # Transformation parameters\n",
    "    pixel_size = settings[dataset][\"pixel_size\"]\n",
    "    x_shift = settings[dataset][\"x_shift\"]\n",
    "    y_shift = settings[dataset][\"y_shift\"]\n",
    "    \n",
    "    # Load DAPI images\n",
    "    files = os.listdir(data_path + \"raw_data/DAPI_images/\")\n",
    "    files = [i for i in files if i.startswith(\"mosaic_DAPI_z\")]\n",
    "    files.sort()\n",
    "    \n",
    "    # Read transcripts\n",
    "    transcripts = pd.read_csv(data_path + \"raw_data/transcripts.csv\")\n",
    "    transcripts = transcripts[[\"cell_id\", \"gene\", \"global_x\", \"global_y\", \"global_z\"]].copy()\n",
    "    \n",
    "    # Compute DAPI pixel coordinates\n",
    "    transcripts[\"row\"] = (transcripts[\"global_y\"] / pixel_size).astype(int) + y_shift\n",
    "    transcripts[\"col\"] = (transcripts[\"global_x\"] / pixel_size).astype(int) + x_shift\n",
    "\n",
    "    # Add default overlap column\n",
    "    transcripts[\"overlaps_nucleus_5_dilation\"] = 0\n",
    "    transcripts[\"overlaps_nucleus_10_dilation\"] = 0\n",
    "    \n",
    "    # Update labels in place\n",
    "    global_ratio = []\n",
    "\n",
    "    for i, radius in enumerate([5, 10]):\n",
    "        \n",
    "        print(f\"Processing dilation radius: {radius}\")\n",
    "\n",
    "        for j, fname in enumerate(files):\n",
    "            \n",
    "            # Load DAPI image\n",
    "            img = tifffile.imread(data_path + f\"raw_data/DAPI_images/{fname}\")\n",
    "            img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "            \n",
    "            # Threshold and dilate\n",
    "            th = adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=radius)\n",
    "\n",
    "            # Save resized visualization (optional)\n",
    "            th_small = cv2.resize(th, (3500, 5000), interpolation=cv2.INTER_AREA)\n",
    "            cv2.imwrite(f\"intermediate_data/images/z_{j}_small.png\", th_small)\n",
    "            \n",
    "            # Select transcripts in this z-layer\n",
    "            trans_z_mask = transcripts[\"global_z\"] == j\n",
    "            trans_z = transcripts[trans_z_mask].copy()\n",
    "            row_vals = trans_z[\"row\"].astype(int).values\n",
    "            col_vals = trans_z[\"col\"].astype(int).values\n",
    "\n",
    "            # Avoid out-of-bounds indexing\n",
    "            height, width = th.shape\n",
    "            valid = (row_vals >= 0) & (row_vals < height) & (col_vals >= 0) & (col_vals < width)\n",
    "            row_valid = row_vals[valid]\n",
    "            col_valid = col_vals[valid]\n",
    "            \n",
    "            # Assign in-nucleus labels\n",
    "            overlaps = np.zeros(len(trans_z), dtype=int)\n",
    "            overlaps[valid] = (th[row_valid, col_valid] != 0).astype(int)\n",
    "\n",
    "            # Update main DataFrame in-place\n",
    "            transcripts.loc[trans_z.index, f\"overlaps_nucleus_{radius}_dilation\"] = overlaps\n",
    "\n",
    "            # Track global ratio\n",
    "            global_ratio.append(overlaps.mean())\n",
    "            print(f\"Iteration {j+1}: {np.sum(row_vals != row_valid)} row mismatches, {np.sum(col_vals != col_valid)} column mismatches, {overlaps.mean():.2%} in-nucleus\")\n",
    "    \n",
    "    print(f\"Average in-nucleus ratio (5 dilation): {transcripts['overlaps_nucleus_5_dilation'].mean()}\")\n",
    "    print(f\"Average in-nucleus ratio (10 dilation): {transcripts['overlaps_nucleus_10_dilation'].mean()}\")\n",
    "    \n",
    "    # Final labeled transcripts\n",
    "    transcripts = transcripts[[\"cell_id\", \"overlaps_nucleus_5_dilation\", \"overlaps_nucleus_10_dilation\", \"gene\", \"global_x\", \"global_y\", \"global_z\"]].copy()\n",
    "    transcripts[\"global_z\"] *= 1.5\n",
    "    transcripts = transcripts.rename(columns = {\"gene\": \"target\"})\n",
    "    \n",
    "    # Cut hemisphere\n",
    "    cutoff = settings[dataset][\"cutoff\"]\n",
    "    theta = settings[dataset][\"theta\"]\n",
    "    coordinate_for_rotation = settings[dataset][\"coordinate_for_rotation\"]\n",
    "    coordinate_for_cutoff = settings[dataset][\"coordinate_for_cutoff\"]\n",
    "    cutoff_direction = settings[dataset][\"cutoff_direction\"]\n",
    "    \n",
    "    rotation_matrix = np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]])\n",
    "    coords = transcripts[coordinate_for_rotation].to_numpy()\n",
    "    transformed_coords = coords @ rotation_matrix.T\n",
    "    transcripts[f\"{coordinate_for_rotation[0]}_new\"] = transformed_coords[:, 0]\n",
    "    transcripts[f\"{coordinate_for_rotation[1]}_new\"] = transformed_coords[:, 1]\n",
    "    if cutoff_direction == \"smaller\":\n",
    "        transcripts_cut = transcripts[transcripts[f\"{coordinate_for_cutoff}_new\"] <= cutoff].copy()\n",
    "    elif cutoff_direction == \"larger\":\n",
    "        transcripts_cut = transcripts[transcripts[f\"{coordinate_for_cutoff}_new\"] >= cutoff].copy()\n",
    "    transcripts_cut = transcripts_cut[[\"cell_id\", in_soma_label, \"target\", \"global_x\", \"global_y\", \"global_z\"]].copy()\n",
    "    transcripts_cut.rename(columns={in_soma_label: \"overlaps_nucleus\"}, inplace=True)\n",
    "\n",
    "    transcripts_cut.to_parquet(data_path + \"processed_data/transcripts.parquet\")\n",
    "    print(f\"Processed {dataset}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cut a small region from the hemisphere\n",
    "# dataset = \"MERSCOPE_WT_1\"\n",
    "# data_path = f\"../data/{dataset}/\"\n",
    "# output_path = f\"../output/{dataset}/\"\n",
    "\n",
    "# # x_min, x_max = 4500, 5500\n",
    "# # y_min, y_max = 3000, 4000\n",
    "\n",
    "# x_min, x_max = 3100, 4100\n",
    "# y_min, y_max = 3100, 4100\n",
    "\n",
    "# adata = sc.read_h5ad(data_path + \"processed_data/adata.h5ad\")\n",
    "\n",
    "# sc.set_figure_params(figsize = (6, 9))\n",
    "# ax = sc.pl.scatter(adata, x=\"global_y_new\", y=\"global_x_new\", color=\"brain_area\", size=10, title = \" \", show=False)\n",
    "# rect = Rectangle((y_min, x_min), y_max - y_min, x_max - x_min, linewidth=2, edgecolor=\"red\", facecolor=\"none\")\n",
    "# ax.add_patch(rect)\n",
    "# ax.grid(False)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# ax.set_xlabel(\"\")\n",
    "# ax.set_ylabel(\"\")\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "# # plt.savefig(output_path +\"small_region_annotation.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "# plt.savefig(output_path +\"small_region_2_annotation.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "# plt.close()\n",
    "\n",
    "# adata_cut = adata[(adata.obs[\"global_y_new\"] >= y_min) & (adata.obs[\"global_y_new\"] <= y_max) & (adata.obs[\"global_x_new\"] >= x_min) & (adata.obs[\"global_x_new\"] <= x_max)].copy()\n",
    "# domains = \"cell_type\"\n",
    "# num_celltype = len(adata_cut.obs[domains].unique())\n",
    "# plot_color = [\"#F56867\",\"#FEB915\",\"#C798EE\",\"#59BE86\",\"#7495D3\",\"#6D1A9C\",\"#15821E\",\"#3A84E6\",\"#997273\",\"#787878\",\"#DB4C6C\",\"#9E7A7A\",\"#554236\",\"#AF5F3C\",\"#93796C\",\"#F9BD3F\",\"#DAB370\",\"#877F6C\",\"#268785\"]\n",
    "# adata_cut.uns[domains+\"_colors\"] = list(plot_color[:num_celltype])\n",
    "\n",
    "# sc.set_figure_params(figsize = (5, 5))\n",
    "# ax = sc.pl.scatter(adata_cut, x=\"global_y_new\", y=\"global_x_new\", color=\"cell_type\", size=15, title = \" \", show=False)\n",
    "# ax.grid(False)\n",
    "# ax.set_xticks([])\n",
    "# ax.set_yticks([])\n",
    "# ax.set_xlabel(\"\")\n",
    "# ax.set_ylabel(\"\")\n",
    "# for spine in ax.spines.values():\n",
    "#     spine.set_visible(False)\n",
    "# # plt.savefig(output_path +\"small_region.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "# plt.savefig(output_path +\"small_region_2.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retain the transcripts in the small region\n",
    "# theta = 10 * np.pi / 180\n",
    "# cutoff = 6250\n",
    "\n",
    "# transcripts = pd.read_parquet(data_path + \"processed_data/transcripts.parquet\")\n",
    "\n",
    "# rotation_matrix = np.array([[np.cos(theta), np.sin(theta)], [-np.sin(theta), np.cos(theta)]])\n",
    "# coords = transcripts[[\"global_y\", \"global_x\"]].to_numpy()\n",
    "# transformed_coords = coords @ rotation_matrix.T\n",
    "# transcripts[\"global_y_new\"] = transformed_coords[:, 0]\n",
    "# transcripts[\"global_x_new\"] = transformed_coords[:, 1]\n",
    "# transcripts[\"global_y_new\"] = cutoff - transcripts[\"global_y_new\"]\n",
    "\n",
    "# transcripts_cut = transcripts[(transcripts[\"global_y_new\"] >= y_min) & (transcripts[\"global_y_new\"] <= y_max) & (transcripts[\"global_x_new\"] >= x_min) & (transcripts[\"global_x_new\"] <= x_max)].copy()\n",
    "# # transcripts_cut.to_parquet(data_path + \"processed_data/transcripts_small_region.parquet\")\n",
    "# transcripts_cut.to_parquet(data_path + \"processed_data/transcripts_small_region_2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcDETECT-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
