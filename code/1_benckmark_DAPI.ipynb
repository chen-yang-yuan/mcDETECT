{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0756a232",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import pyvips\n",
        "import seaborn as sns\n",
        "import tifffile\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91d81aee",
      "metadata": {},
      "source": [
        "### Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990a340d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# File paths\n",
        "dataset = \"MERSCOPE_WT_1\"\n",
        "data_path = f\"../data/{dataset}/\"\n",
        "output_path = f\"../output/{dataset}/\"\n",
        "\n",
        "# Transformation parameters\n",
        "pixel_size = 0.10799861\n",
        "x_shift = int(-266.1734)\n",
        "y_shift = int(180.2510)\n",
        "\n",
        "# All DAPI images\n",
        "files = os.listdir(data_path + \"raw_data/DAPI_images/\")\n",
        "files = [i for i in files if i.startswith(\"mosaic\")]\n",
        "files.sort()\n",
        "files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d213bca",
      "metadata": {},
      "source": [
        "### Derive the MIP of DAPI images (run once)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83822b3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# paths = [data_path + \"raw_data/DAPI_images/\" + f\"mosaic_DAPI_z{i}.tif\" for i in range(7)]\n",
        "# imgs = [pyvips.Image.new_from_file(p, access=\"sequential\") for p in paths]\n",
        "# mip = imgs[0]\n",
        "# for im in imgs[1:]:\n",
        "#     mip = pyvips.Image.maxpair(mip, im)\n",
        "# mip.tiffsave(\n",
        "#     data_path + \"raw_data/DAPI_images/mosaic_DAPI_MIP.tif\",\n",
        "#     bigtiff=True,\n",
        "#     compression=\"lzw\",   # or \"deflate\"\n",
        "#     tile=True,\n",
        "#     tile_width=1024,\n",
        "#     tile_height=1024,\n",
        "#     pyramid=False\n",
        "# )\n",
        "# print(\"Saved:\", \"mosaic_DAPI_MIP.tif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "393e1aeb",
      "metadata": {},
      "source": [
        "### Benchmark 1: area of detected objects on the MIP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0813b103",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== Helper functions ==================== #\n",
        "\n",
        "\n",
        "# Thresholding followed by dilation with circular kernel\n",
        "def adaptive_thresholding_with_dilation(img, block_size=49, c=-1, radius=10):\n",
        "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(th, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "def adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=50, radius=10):\n",
        "    th = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, block_size, c)\n",
        "    contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    filtered_contours = [c for c in contours if cv2.contourArea(c) >= min_area]\n",
        "    filtered_img = np.zeros_like(th)\n",
        "    cv2.drawContours(filtered_img, filtered_contours, -1, 255, -1)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(filtered_img, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "def otsu_with_dilation(img, radius=10):\n",
        "    _, th = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*radius+1, 2*radius+1))\n",
        "    th_dilated = cv2.dilate(th, kernel)\n",
        "    return th_dilated\n",
        "\n",
        "\n",
        "# Analyze detected objects\n",
        "def analyze_objects(contours, method_name):\n",
        "    objects = []\n",
        "    for i, contour in enumerate(contours):\n",
        "        area_pixels = cv2.contourArea(contour)\n",
        "        if area_pixels > 0:\n",
        "            area_um2 = area_pixels * (pixel_size ** 2)\n",
        "            radius_um = np.sqrt(area_um2 / np.pi)\n",
        "            diameter_um = radius_um * 2\n",
        "            objects.append({\"method\": method_name,\n",
        "                            \"object_id\": i + 1,\n",
        "                            \"area_pixels\": area_pixels,\n",
        "                            \"area_um2\": area_um2,\n",
        "                            \"radius_um\": radius_um,\n",
        "                            \"diameter_um\": diameter_um})\n",
        "    return objects\n",
        "\n",
        "\n",
        "def print_method_results(objects, method_name):\n",
        "    \n",
        "    if len(objects) > 0:\n",
        "        \n",
        "        print(f\"Number of detected objects: {len(objects)}\")\n",
        "        print(f\"\\nDetailed statistics for each object:\")\n",
        "        \n",
        "        areas_px = [obj[\"area_pixels\"] for obj in objects]\n",
        "        areas_um2 = [obj[\"area_um2\"] for obj in objects]\n",
        "        radii_um = [obj[\"radius_um\"] for obj in objects]\n",
        "        diameters_um = [obj[\"diameter_um\"] for obj in objects]\n",
        "        \n",
        "        print(f\"\\nSummary statistics:\")\n",
        "        print(f\"  Area (pixels²):  Mean={np.mean(areas_px):6.1f}, Median={np.median(areas_px):6.1f}, Min={np.min(areas_px):6.1f}, Max={np.max(areas_px):6.1f}\")\n",
        "        print(f\"  Area (μm²):      Mean={np.mean(areas_um2):6.2f}, Median={np.median(areas_um2):6.2f}, Min={np.min(areas_um2):6.2f}, Max={np.max(areas_um2):6.2f}\")\n",
        "        print(f\"  Radius (μm):     Mean={np.mean(radii_um):6.2f}, Median={np.median(radii_um):6.2f}, Min={np.min(radii_um):6.2f}, Max={np.max(radii_um):6.2f}\")\n",
        "        print(f\"  Diameter (μm):   Mean={np.mean(diameters_um):6.2f}, Median={np.median(diameters_um):6.2f}, Min={np.min(diameters_um):6.2f}, Max={np.max(diameters_um):6.2f}\")\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        print(f\"No objects detected with {method_name}!\")\n",
        "\n",
        "\n",
        "# Extract statistics for plotting\n",
        "def get_method_statistics(method_results, method_name, stat_type=\"area_pixels\"):\n",
        "    if method_name not in method_results:\n",
        "        print(f\"Method '{method_name}' not found in results\")\n",
        "        return []\n",
        "    objects = method_results[method_name][\"objects\"]\n",
        "    return [obj[stat_type] for obj in objects]\n",
        "\n",
        "\n",
        "def get_all_methods_statistics(method_results, stat_type=\"area_pixels\"):\n",
        "    stats_dict = {}\n",
        "    for method_name in method_results.keys():\n",
        "        stats_dict[method_name] = get_method_statistics(method_results, method_name, stat_type)\n",
        "    return stats_dict\n",
        "\n",
        "\n",
        "# Downsample image\n",
        "def downsample_image(img, scale_factor=5000):\n",
        "    height, width = img.shape[:2]\n",
        "    if height < width:\n",
        "        scale_factor = 5000 / height\n",
        "        new_height = 5000\n",
        "        new_width = int(width * scale_factor)\n",
        "    else:\n",
        "        scale_factor = 5000 / width\n",
        "        new_width = 5000\n",
        "        new_height = int(height * scale_factor)\n",
        "    return cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d470d223",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize for comparison\n",
        "fname = \"mosaic_DAPI_MIP.tif\"\n",
        "\n",
        "# Load DAPI image, downsample, and save representative patch\n",
        "img_path = os.path.join(data_path, \"raw_data/DAPI_images\", fname)\n",
        "img = tifffile.imread(img_path)\n",
        "img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "\n",
        "img_downsampled = downsample_image(img, scale_factor=5000)\n",
        "cv2.imwrite(output_path + f\"downsampled_img.png\", img_downsampled)\n",
        "\n",
        "target_coords = [(3750, 1500), (3750, 1650), (3750, 1800)]\n",
        "w, h = 150, 150\n",
        "for i, (x0, y0) in enumerate(target_coords):\n",
        "    patch = img_downsampled[y0:y0+h, x0:x0+w]\n",
        "    cv2.imwrite(output_path + f\"downsampled_patch_{i}.png\", patch)\n",
        "\n",
        "print(f\"Analyzing DAPI image: {fname}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define thresholding methods\n",
        "thresholding_methods = {\n",
        "    \"Adaptive Thresholding\": {\n",
        "        \"function\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 49, -1),\n",
        "        \"description\": \"Gaussian-weighted adaptive thresholding with block size 49\"\n",
        "    },\n",
        "    \"Adaptive + Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_dilation(img, block_size=49, c=-1, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Small Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=5),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Large Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=15),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    # \"Adaptive + Moderate Size Filter + Small Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=5),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=250px)\"\n",
        "    # },\n",
        "    # \"Adaptive + Moderate Size Filter + Moderate Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=10),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=250px)\"\n",
        "    # },\n",
        "    # \"Adaptive + Moderate Size Filter + Large Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=250, radius=15),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=250px)\"\n",
        "    # },\n",
        "    # \"Adaptive + Large Size Filter + Small Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=5),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=500px)\"\n",
        "    # },\n",
        "    # \"Adaptive + Large Size Filter + Moderate Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=10),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=500px)\"\n",
        "    # },\n",
        "    # \"Adaptive + Large Size Filter + Large Dilation\": {\n",
        "    #     \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=500, radius=15),\n",
        "    #     \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=15px) and size filter (min_area=500px)\"\n",
        "    # },\n",
        "    # \"Otsu Thresholding\": {\n",
        "    #     \"function\": lambda img: cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1],\n",
        "    #     \"description\": \"Automatic global thresholding using Otsu's method\"\n",
        "    # },\n",
        "    # \"Otsu + Dilation\": {\n",
        "    #     \"function\": lambda img: otsu_with_dilation(img, radius=10),\n",
        "    #     \"description\": \"Otsu thresholding followed by dilation with circular kernel (radius=10px)\"\n",
        "    # },\n",
        "}\n",
        "\n",
        "print(f\"Total methods available: {list(thresholding_methods.keys())}\")\n",
        "\n",
        "# Main analysis loop\n",
        "all_results = {}\n",
        "\n",
        "for i, (method_name, method_info) in enumerate(thresholding_methods.items()):\n",
        "    print(f\"METHOD {i+1}: {method_name.upper()}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Description: {method_info['description']}\")\n",
        "    \n",
        "    # Apply thresholding method\n",
        "    thresholded_img = method_info[\"function\"](img)\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(thresholded_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    # Save downsampled thresholded image\n",
        "    thresholded_img_downsampled = downsample_image(thresholded_img, scale_factor=5000)\n",
        "    safe_filename = method_name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    cv2.imwrite(output_path + f\"thresholded_img_{safe_filename}_downsampled.png\", thresholded_img_downsampled)\n",
        "    \n",
        "    for i, (x0, y0) in enumerate(target_coords):\n",
        "        patch = thresholded_img_downsampled[y0:y0+h, x0:x0+w]\n",
        "        cv2.imwrite(output_path + f\"thresholded_patch_{safe_filename}_downsampled_{i}.png\", patch)\n",
        "    \n",
        "    # Analyze objects\n",
        "    objects = analyze_objects(contours, method_name)\n",
        "    \n",
        "    # Print results\n",
        "    print_method_results(objects, method_name)\n",
        "    \n",
        "    # Store results\n",
        "    all_results[method_name] = {\n",
        "        \"objects\": objects,\n",
        "        \"thresholded_image\": thresholded_img,\n",
        "        \"num_objects\": len(objects)\n",
        "    }\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Method Comparison Summary\n",
        "print(\"COMPARISON SUMMARY\")\n",
        "print(\"-\" * 40)\n",
        "for method_name, results in all_results.items():\n",
        "    print(f\"{method_name}: {results['num_objects']} objects detected\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "# Store results for further analysis\n",
        "method_results = all_results\n",
        "with open(output_path + \"method_results.pickle\", \"wb\") as handle:\n",
        "    pickle.dump(method_results, handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a0aeeff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save object areas\n",
        "areas_um2 = get_all_methods_statistics(method_results, \"area_um2\")\n",
        "pd.DataFrame({\"area\": areas_um2[\"Adaptive + Small Size Filter + Small Dilation\"]}).to_csv(\"../validation/areas_MERSCOPE_small_size_small_dilation.csv\", index=False)\n",
        "pd.DataFrame({\"area\": areas_um2[\"Adaptive + Small Size Filter + Moderate Dilation\"]}).to_csv(\"../validation/areas_MERSCOPE_small_size_moderate_dilation.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2594ad6",
      "metadata": {},
      "source": [
        "### Benchmark 2: in-soma ratio of transcripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fcbdc0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read transcripts\n",
        "transcripts = pd.read_csv(data_path + \"raw_data/transcripts.csv\")\n",
        "transcripts = transcripts[[\"cell_id\", \"gene\", \"global_x\", \"global_y\", \"global_z\"]].copy()\n",
        "transcripts.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1b8036",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define target genes\n",
        "all_genes = pd.read_csv(data_path + \"processed_data/genes.csv\")\n",
        "all_genes = all_genes[\"genes\"].tolist()\n",
        "\n",
        "with open(\"../data/utils/overlap_genes.pickle\", \"rb\") as handle:\n",
        "    overlap_genes = pickle.load(handle)\n",
        "granule_markers = overlap_genes[\"overlap_genes_select\"]\n",
        "\n",
        "transcripts = transcripts[transcripts[\"gene\"].isin(all_genes)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30aa53e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==================== Thresholding Methods Benchmarking ====================#\n",
        "\n",
        "# Define thresholding methods\n",
        "thresholding_methods = {\n",
        "    \"Adaptive Thresholding\": {\n",
        "        \"function\": lambda img: cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 49, -1),\n",
        "        \"description\": \"Gaussian-weighted adaptive thresholding with block size 49\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Small Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=5),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=5px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "    \"Adaptive + Small Size Filter + Moderate Dilation\": {\n",
        "        \"function\": lambda img: adaptive_thresholding_with_size_filter_and_dilation(img, block_size=49, c=-1, min_area=100, radius=10),\n",
        "        \"description\": \"Adaptive thresholding followed by dilation with circular kernel (radius=10px) and size filter (min_area=100px)\"\n",
        "    },\n",
        "}\n",
        "\n",
        "# Initialize transcript dataframe with binary columns for each method\n",
        "transcripts_with_labels = transcripts.copy()\n",
        "for method_name in thresholding_methods.keys():\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    transcripts_with_labels[f\"in_soma_{safe_col_name}\"] = 0\n",
        "\n",
        "print(\"Starting thresholding methods benchmarking...\\n\")\n",
        "\n",
        "# Process each z-layer (exclude MIP file)\n",
        "z_layer_files = [f for f in files if f.startswith(\"mosaic_DAPI_z\")]\n",
        "z_layer_files.sort()\n",
        "\n",
        "# Process each thresholding method\n",
        "for method_idx, (method_name, method_info) in enumerate(thresholding_methods.items()):\n",
        "    print(f\"Processing method {method_idx+1}/{len(thresholding_methods)}: {method_name}\")\n",
        "    \n",
        "    # Get safe column name for this method\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    in_soma_col = f\"in_soma_{safe_col_name}\"\n",
        "    \n",
        "    for j, fname in enumerate(z_layer_files):\n",
        "        # Load DAPI image\n",
        "        img_path = os.path.join(data_path, \"raw_data/DAPI_images\", fname)\n",
        "        img = tifffile.imread(img_path)\n",
        "        img = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
        "        \n",
        "        # Apply thresholding method\n",
        "        th = method_info[\"function\"](img)\n",
        "        \n",
        "        # Map transcripts to this z-layer and check overlap\n",
        "        trans_z_mask = transcripts[\"global_z\"] == j\n",
        "        trans_z_indices = transcripts.index[trans_z_mask].values\n",
        "        \n",
        "        if len(trans_z_indices) > 0:\n",
        "            # Calculate row and col from global_x and global_y\n",
        "            # Convert global coordinates (in microns) to pixel coordinates\n",
        "            global_x_vals = transcripts.loc[trans_z_indices, \"global_x\"].values\n",
        "            global_y_vals = transcripts.loc[trans_z_indices, \"global_y\"].values\n",
        "            \n",
        "            # Convert to pixel coordinates (divide by pixel_size and apply shifts)\n",
        "            col_vals = (global_x_vals / pixel_size).astype(int) + x_shift\n",
        "            row_vals = (global_y_vals / pixel_size).astype(int) + y_shift\n",
        "            \n",
        "            # Visualize mapped transcripts for first DAPI image only\n",
        "            if method_idx == 0 and j == 0:\n",
        "                # Filter transcripts for Slc17a7 gene\n",
        "                gene_mask = transcripts.loc[trans_z_indices, \"gene\"] == \"Slc17a7\"\n",
        "                gene_local_indices = np.where(gene_mask)[0]  # Indices within trans_z_indices\n",
        "                \n",
        "                if len(gene_local_indices) > 0:\n",
        "                    # Get coordinates for Slc17a7 transcripts using already calculated values\n",
        "                    gene_col = col_vals[gene_local_indices]\n",
        "                    gene_row = row_vals[gene_local_indices]\n",
        "                    \n",
        "                    # Create color version of DAPI image\n",
        "                    img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "                    \n",
        "                    # Draw red dots for Slc17a7 transcripts\n",
        "                    height, width = img_color.shape[:2]\n",
        "                    for r, c in zip(gene_row, gene_col):\n",
        "                        if 0 <= r < height and 0 <= c < width:\n",
        "                            cv2.circle(img_color, (c, r), 5, (0, 0, 255), -1)  # Red dot, radius 5\n",
        "                    \n",
        "                    # Downsample the annotated image\n",
        "                    img_downsampled = downsample_image(img_color, scale_factor=5000)\n",
        "                    \n",
        "                    # Save the downsampled annotated image\n",
        "                    output_filename = f\"mapped_transcripts_Slc17a7_z{j}_{safe_col_name}.png\"\n",
        "                    output_filepath = os.path.join(output_path, output_filename)\n",
        "                    cv2.imwrite(output_filepath, img_downsampled)\n",
        "                    print(f\"  Saved visualization to: {output_filename}\")\n",
        "            \n",
        "            # Avoid out-of-bounds indexing\n",
        "            height, width = th.shape\n",
        "            valid = (row_vals >= 0) & (row_vals < height) & (col_vals >= 0) & (col_vals < width)\n",
        "            row_valid = row_vals[valid]\n",
        "            col_valid = col_vals[valid]\n",
        "            valid_indices = trans_z_indices[valid]\n",
        "            \n",
        "            # Check overlap for valid transcripts\n",
        "            if len(row_valid) > 0:\n",
        "                overlaps = (th[row_valid, col_valid] != 0).astype(int)\n",
        "                # Update in-soma labels in the transcript dataframe\n",
        "                transcripts_with_labels.loc[valid_indices, in_soma_col] = overlaps\n",
        "\n",
        "print(\"Completed processing all methods.\\n\")\n",
        "\n",
        "# Calculate per-gene in-soma ratios for each method\n",
        "gene_ratios = []\n",
        "\n",
        "for method_name in thresholding_methods.keys():\n",
        "    safe_col_name = method_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\",\", \"\").replace(\"+\", \"and\")\n",
        "    in_soma_col = f\"in_soma_{safe_col_name}\"\n",
        "    \n",
        "    # Group by gene and calculate in-soma ratio\n",
        "    gene_stats = transcripts_with_labels.groupby(\"gene\").agg({\n",
        "        in_soma_col: [\"sum\", \"count\"]\n",
        "    }).reset_index()\n",
        "    gene_stats.columns = [\"gene\", \"in_soma_count\", \"total_count\"]\n",
        "    gene_stats[\"in_soma_ratio\"] = gene_stats[\"in_soma_count\"] / gene_stats[\"total_count\"]\n",
        "    gene_stats[\"method\"] = method_name\n",
        "    \n",
        "    gene_ratios.append(gene_stats)\n",
        "\n",
        "# Combine all gene ratios\n",
        "gene_ratios_df = pd.concat(gene_ratios, ignore_index=True)\n",
        "\n",
        "# Add gene category labels\n",
        "gene_ratios_df[\"gene_category\"] = \"Others\"\n",
        "gene_ratios_df.loc[gene_ratios_df[\"gene\"].isin(granule_markers), \"gene_category\"] = \"Granule Markers\"\n",
        "\n",
        "# Save transcript file with in-soma labels\n",
        "transcripts_output_path = os.path.join(data_path, \"processed_data\", \"transcripts_with_in_soma_labels.parquet\")\n",
        "transcripts_with_labels.to_parquet(transcripts_output_path)\n",
        "print(f\"Transcripts with in-soma labels saved to: {transcripts_output_path}\")\n",
        "\n",
        "# Save gene-level in-soma ratios\n",
        "gene_ratios_output_path = os.path.join(output_path, \"gene_in_soma_ratios.csv\")\n",
        "gene_ratios_df.to_csv(gene_ratios_output_path, index=False)\n",
        "print(f\"Gene-level in-soma ratios saved to: {gene_ratios_output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def99c08",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mcDETECT-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
